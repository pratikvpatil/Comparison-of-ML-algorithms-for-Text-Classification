{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.testing._private'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c9ecb00848f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[1;31m# avoid flakes unused variable error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# Pytest testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytesttester\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.testing._private'"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics Vidhya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ENTJ    1\n",
       "ENTP    1\n",
       "INFJ    3\n",
       "INTJ    3\n",
       "INTP    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"mbti_1.csv\")\n",
    "\n",
    "df = df.iloc[0:10,:]\n",
    "df.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4652"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['posts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = df['posts']\n",
    "trainDF['label'] = df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2758)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,5), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2758)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_tfidf.tocsc().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '04',\n",
       " '05',\n",
       " '07',\n",
       " '08',\n",
       " '1',\n",
       " '10',\n",
       " '11',\n",
       " '127',\n",
       " '140s',\n",
       " '15',\n",
       " '18',\n",
       " '2',\n",
       " '20',\n",
       " '2010',\n",
       " '201011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2015',\n",
       " '20s',\n",
       " '20th',\n",
       " '218106',\n",
       " '221226',\n",
       " '22842206',\n",
       " '236994',\n",
       " '23700',\n",
       " '24',\n",
       " '246386',\n",
       " '25',\n",
       " '256818',\n",
       " '26',\n",
       " '29',\n",
       " '2921aa070866f20450f8e1160b1e5d41',\n",
       " '2cs4ew',\n",
       " '2nkcn8m9m0m',\n",
       " '2r2nrv4ve1o',\n",
       " '2xhgqisd040',\n",
       " '3',\n",
       " '30',\n",
       " '300x225',\n",
       " '30am',\n",
       " '32560474',\n",
       " '338',\n",
       " '349890',\n",
       " '35',\n",
       " '351',\n",
       " '357002',\n",
       " '358',\n",
       " '358882',\n",
       " '358890',\n",
       " '367034',\n",
       " '368',\n",
       " '37',\n",
       " '376562',\n",
       " '385',\n",
       " '3x',\n",
       " '4',\n",
       " '400',\n",
       " '41',\n",
       " '450',\n",
       " '46',\n",
       " '49142',\n",
       " '4v2uyorhqok',\n",
       " '4w3',\n",
       " '5',\n",
       " '50',\n",
       " '5am',\n",
       " '6',\n",
       " '6020d1f9da6944a6b71bbe6',\n",
       " '629346',\n",
       " '6422',\n",
       " '651762',\n",
       " '66314',\n",
       " '66vc',\n",
       " '6xxfqprg4tq',\n",
       " '6yro4',\n",
       " '70',\n",
       " '700049',\n",
       " '700057',\n",
       " '712170',\n",
       " '712178',\n",
       " '712186',\n",
       " '712194',\n",
       " '718282',\n",
       " '718290',\n",
       " '718298',\n",
       " '718306',\n",
       " '718314',\n",
       " '7ghqoyxmaue',\n",
       " '7hcyx_y5xdo',\n",
       " '7pm',\n",
       " '7s',\n",
       " '7w8',\n",
       " '7yrs',\n",
       " '8',\n",
       " '813a0c6243814cab84c51',\n",
       " '84389',\n",
       " '84390',\n",
       " '8s',\n",
       " '9',\n",
       " '90',\n",
       " '9uhldwcqsqq',\n",
       " '9utptpxpige',\n",
       " '_____',\n",
       " 'a',\n",
       " 'abandoned',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrupt',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abuse',\n",
       " 'accepted',\n",
       " 'accidents',\n",
       " 'accomplished',\n",
       " 'according',\n",
       " 'accurate',\n",
       " 'aces',\n",
       " 'achieving',\n",
       " 'acid',\n",
       " 'acknowledge',\n",
       " 'acknowledging',\n",
       " 'acoustic',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acutely',\n",
       " 'add',\n",
       " 'addictive',\n",
       " 'address',\n",
       " 'admiration',\n",
       " 'admit',\n",
       " 'adobe',\n",
       " 'adultdvdtalk',\n",
       " 'advancement',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'affectionate',\n",
       " 'affects',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agonizingly',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'aic',\n",
       " 'air',\n",
       " 'akfmyglhwwk',\n",
       " 'alarming',\n",
       " 'albums',\n",
       " 'alcatraz',\n",
       " 'ales',\n",
       " 'alexxxandra',\n",
       " 'alexxxandra97',\n",
       " 'all',\n",
       " 'allen',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alphonse',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'althought',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'ambiguous',\n",
       " 'amended',\n",
       " 'amott',\n",
       " 'amuse',\n",
       " 'amuses',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'analyse',\n",
       " 'analysis',\n",
       " 'anarchy',\n",
       " 'and',\n",
       " 'and9gcsda',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'animedreaming',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'antp',\n",
       " 'anxiety',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apis',\n",
       " 'apollo',\n",
       " 'apologetic',\n",
       " 'apparently',\n",
       " 'appearance',\n",
       " 'appears',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'arbitrary',\n",
       " 'arch',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arises',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrogant',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'arya',\n",
       " 'as',\n",
       " 'asahina',\n",
       " 'ascientologists',\n",
       " 'ashton',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assassins',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'asshole',\n",
       " 'assimilate',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'assumptions',\n",
       " 'at',\n",
       " 'atcha',\n",
       " 'ate',\n",
       " 'atheist',\n",
       " 'atheists',\n",
       " 'atmosphere',\n",
       " 'attaching',\n",
       " 'attachment',\n",
       " 'attainable',\n",
       " 'attaining',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'aug',\n",
       " 'auto',\n",
       " 'automatically',\n",
       " 'avatar',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'awake',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awhile',\n",
       " 'ayn',\n",
       " 'b',\n",
       " 'baaaaaaaaccckkkk',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backstab',\n",
       " 'backyard',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badly',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'banger',\n",
       " 'banish',\n",
       " 'bankrupt',\n",
       " 'banned',\n",
       " 'barely',\n",
       " 'barges',\n",
       " 'baring',\n",
       " 'barmy',\n",
       " 'barriers',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'batty',\n",
       " 'bbc',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beat',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becuase',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'beetle',\n",
       " 'beetlejuice',\n",
       " 'before',\n",
       " 'beggning',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behaviour',\n",
       " 'being',\n",
       " 'beings',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'believer',\n",
       " 'below',\n",
       " 'bemoan',\n",
       " 'benefit',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bewildered',\n",
       " 'beyond',\n",
       " 'biased',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'billion',\n",
       " 'binged',\n",
       " 'birth',\n",
       " 'bit',\n",
       " 'bitches',\n",
       " 'black',\n",
       " 'bleak',\n",
       " 'blessing',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogspot',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blushed',\n",
       " 'boa',\n",
       " 'board',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'boi',\n",
       " 'bolded',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'books',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bottle',\n",
       " 'bounce',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boxy',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boyish',\n",
       " 'brain',\n",
       " 'brainstorm',\n",
       " 'brave',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breather',\n",
       " 'brevity',\n",
       " 'brian_snowflake',\n",
       " 'briggs',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broke',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brown',\n",
       " 'browse',\n",
       " 'browsing',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bunch',\n",
       " 'burgeoning',\n",
       " 'burst',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'c',\n",
       " 'calculating',\n",
       " 'call',\n",
       " 'callaendia',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'can',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cantrell',\n",
       " 'capitalize',\n",
       " 'car',\n",
       " 'care',\n",
       " 'cares',\n",
       " 'caring',\n",
       " 'carrying',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cavemen',\n",
       " 'celestial',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chair',\n",
       " 'chalk',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changing',\n",
       " 'character',\n",
       " 'characterised',\n",
       " 'characteristics',\n",
       " 'charlie',\n",
       " 'chased',\n",
       " 'check',\n",
       " 'checklist',\n",
       " 'checks',\n",
       " 'cheeky',\n",
       " 'cheerful',\n",
       " 'cheesecake',\n",
       " 'chemistry',\n",
       " 'cherish',\n",
       " 'cheshirewolf',\n",
       " 'chicken',\n",
       " 'chihuahua',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chimes',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'chosen',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'church',\n",
       " 'ciders',\n",
       " 'circles',\n",
       " 'circumstance',\n",
       " 'claim',\n",
       " 'claims',\n",
       " 'class',\n",
       " 'cleaning',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'climb',\n",
       " 'clip',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'club',\n",
       " 'cms',\n",
       " 'co',\n",
       " 'code',\n",
       " 'codger',\n",
       " 'coffee',\n",
       " 'cognition',\n",
       " 'cognitive',\n",
       " 'collect',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combining',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comics',\n",
       " 'coming',\n",
       " 'commented',\n",
       " 'commenting',\n",
       " 'comments',\n",
       " 'committing',\n",
       " 'common',\n",
       " 'communicates',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compensated',\n",
       " 'compilations',\n",
       " 'completely',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'compliment',\n",
       " 'complimentary',\n",
       " 'comprehension',\n",
       " 'concentration',\n",
       " 'concept',\n",
       " 'concerning',\n",
       " 'concerts',\n",
       " 'condescending',\n",
       " 'confessed',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'connects',\n",
       " 'conscientiousness',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'constructed',\n",
       " 'constructs',\n",
       " 'contend',\n",
       " 'content',\n",
       " 'contentment',\n",
       " 'context',\n",
       " 'contexts',\n",
       " 'contribute',\n",
       " 'control',\n",
       " 'controlling',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'converse',\n",
       " 'conversing',\n",
       " 'convey',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'coordination',\n",
       " 'copying',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'correct',\n",
       " 'correlate',\n",
       " 'cosmic',\n",
       " 'cosmicstorm',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'countenance',\n",
       " 'countless',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'cowgirl',\n",
       " 'cows',\n",
       " 'cran',\n",
       " 'crappy',\n",
       " 'crave',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'creatively',\n",
       " 'creator',\n",
       " 'creatures',\n",
       " 'creep',\n",
       " 'crickets',\n",
       " 'cried',\n",
       " 'critical',\n",
       " 'critically',\n",
       " 'crossed',\n",
       " 'crowded',\n",
       " 'crunch',\n",
       " 'crush',\n",
       " 'crushable',\n",
       " 'cry',\n",
       " 'crying',\n",
       " 'cu8qsc1wlie',\n",
       " 'culmination',\n",
       " 'cup',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curse',\n",
       " 'cuz',\n",
       " 'd',\n",
       " 'd5abdxpvbr0',\n",
       " 'daenerys',\n",
       " 'daily',\n",
       " 'damn',\n",
       " 'dancing',\n",
       " 'dany',\n",
       " 'dark',\n",
       " 'darth',\n",
       " 'dat',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dccrupcdb1w',\n",
       " 'dd',\n",
       " 'dead',\n",
       " 'deadly',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dealt',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'deathgrip',\n",
       " 'deathgripbw',\n",
       " 'debate',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decisions',\n",
       " 'decisive',\n",
       " 'declares',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'deer',\n",
       " 'default',\n",
       " 'define',\n",
       " 'defined',\n",
       " 'definite',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'deities',\n",
       " 'delicious',\n",
       " 'denial',\n",
       " 'denver',\n",
       " 'dependant',\n",
       " 'dependency',\n",
       " 'depends',\n",
       " 'deposition',\n",
       " 'depression',\n",
       " 'depth',\n",
       " 'depths',\n",
       " 'describe',\n",
       " 'described',\n",
       " 'description',\n",
       " 'desert',\n",
       " 'deserts',\n",
       " 'deserve',\n",
       " 'design',\n",
       " 'designated',\n",
       " 'desire',\n",
       " 'desired',\n",
       " 'desk',\n",
       " 'desktop',\n",
       " 'despicable',\n",
       " 'destroying',\n",
       " 'detail',\n",
       " 'details',\n",
       " 'detective',\n",
       " 'determined',\n",
       " 'determining',\n",
       " 'developed',\n",
       " 'deviantart',\n",
       " 'devil',\n",
       " 'devils',\n",
       " 'diagnosis',\n",
       " 'diary',\n",
       " 'dichotomy',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'died',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dig',\n",
       " 'dipped',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'dirty',\n",
       " 'dirtywinch',\n",
       " 'disagree',\n",
       " 'disagrees',\n",
       " 'disbelief',\n",
       " 'discipline',\n",
       " 'discover',\n",
       " 'discovermagazine',\n",
       " 'disdain',\n",
       " 'dishonesty',\n",
       " 'disick',\n",
       " 'disinclined',\n",
       " 'dislike',\n",
       " 'dispense',\n",
       " 'disposal',\n",
       " 'disproved',\n",
       " 'distance',\n",
       " 'distinction',\n",
       " 'distorted',\n",
       " 'distracted',\n",
       " 'distress',\n",
       " 'disturbed',\n",
       " 'disturbing',\n",
       " 'ditto',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dogmas',\n",
       " 'doing',\n",
       " 'dollars',\n",
       " 'dominant',\n",
       " 'dominate',\n",
       " 'dominates',\n",
       " 'domination',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'dormer',\n",
       " 'dornob',\n",
       " 'double',\n",
       " 'doublethink',\n",
       " 'doubt',\n",
       " 'douchebags',\n",
       " 'down',\n",
       " 'downed',\n",
       " 'download',\n",
       " 'downloaded',\n",
       " 'dozens',\n",
       " 'dp',\n",
       " 'dr',\n",
       " 'draco',\n",
       " 'drank',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'dream',\n",
       " 'dreamer',\n",
       " 'dreaming',\n",
       " 'dreams',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'drop',\n",
       " 'drowning',\n",
       " 'drug',\n",
       " 'dry',\n",
       " 'duck',\n",
       " 'due',\n",
       " 'dull',\n",
       " 'dumbstruck',\n",
       " 'dumped',\n",
       " 'dumps',\n",
       " 'dunces',\n",
       " 'duper',\n",
       " 'duplicitous',\n",
       " 'e',\n",
       " 'e4dt8fj2ge0',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easier',\n",
       " 'easiest',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'edgar',\n",
       " 'edge',\n",
       " 'edged',\n",
       " 'edges',\n",
       " 'edibles',\n",
       " 'edit',\n",
       " 'education',\n",
       " 'eff',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'egj0y8qs',\n",
       " 'eharmony',\n",
       " 'either',\n",
       " 'elaborate',\n",
       " 'electronic',\n",
       " 'else',\n",
       " 'embrace',\n",
       " 'emil',\n",
       " 'emma',\n",
       " 'emoticons',\n",
       " 'emotional',\n",
       " 'emotionally',\n",
       " 'emotions',\n",
       " 'emphasizing',\n",
       " 'employee',\n",
       " 'employer',\n",
       " 'encompass',\n",
       " 'encounter',\n",
       " 'encountered',\n",
       " 'encourage',\n",
       " 'encourages',\n",
       " 'encrypted',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ends',\n",
       " 'enduring',\n",
       " 'enemy',\n",
       " 'energy',\n",
       " 'enfj7',\n",
       " 'enfp',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enneatype',\n",
       " 'enough',\n",
       " 'entertain',\n",
       " 'entire',\n",
       " 'entitled',\n",
       " 'entj',\n",
       " 'entjs',\n",
       " 'entp',\n",
       " 'entps',\n",
       " 'environment',\n",
       " 'environments',\n",
       " 'envisioning',\n",
       " 'episode',\n",
       " 'episodes',\n",
       " 'equal',\n",
       " 'equate',\n",
       " 'equipment',\n",
       " 'erupt',\n",
       " 'escalated',\n",
       " 'escape',\n",
       " 'esfj',\n",
       " 'esfp',\n",
       " 'esoteric',\n",
       " 'especially',\n",
       " 'essence',\n",
       " 'establish',\n",
       " 'esteem',\n",
       " 'estimate',\n",
       " 'estj',\n",
       " 'estps',\n",
       " 'evej',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'evidently',\n",
       " 'evil',\n",
       " 'exact',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exception',\n",
       " 'excruciatingly',\n",
       " 'exfp',\n",
       " 'existence',\n",
       " 'existential',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiences',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explaining',\n",
       " 'explains',\n",
       " 'explanation',\n",
       " 'explore',\n",
       " 'explosions',\n",
       " 'expose',\n",
       " 'express',\n",
       " 'expression',\n",
       " 'externally',\n",
       " 'extj',\n",
       " 'extra',\n",
       " 'extraversion',\n",
       " 'extravert',\n",
       " 'extraverted',\n",
       " 'extremely',\n",
       " 'extrovert',\n",
       " 'eye',\n",
       " 'f',\n",
       " 'fabi',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'faces',\n",
       " 'facial',\n",
       " 'fact',\n",
       " 'facts',\n",
       " 'failed',\n",
       " 'failure',\n",
       " 'fake',\n",
       " 'faking',\n",
       " 'fall',\n",
       " 'familiar',\n",
       " 'fan',\n",
       " 'fantasized',\n",
       " 'fantasy',\n",
       " 'far',\n",
       " 'fascinating',\n",
       " 'fascination',\n",
       " 'fashion',\n",
       " 'father',\n",
       " 'fatigue',\n",
       " 'faucet',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'fe',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'feelin',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'feels',\n",
       " 'feely',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'females',\n",
       " 'festival',\n",
       " 'festivals',\n",
       " 'few',\n",
       " 'ff_6bf37fi0',\n",
       " 'fhigbolffgw',\n",
       " 'fi',\n",
       " 'fiction',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'figuring',\n",
       " 'files',\n",
       " 'films',\n",
       " 'finally',\n",
       " 'fincher',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'fingertips',\n",
       " 'finish',\n",
       " 'fire',\n",
       " 'fired',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'five',\n",
       " 'flat',\n",
       " 'fledged',\n",
       " 'fleeting',\n",
       " 'flip',\n",
       " 'flirt',\n",
       " 'flirting',\n",
       " 'flying',\n",
       " 'flynn',\n",
       " 'fo',\n",
       " 'focus',\n",
       " 'folder',\n",
       " 'folding',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'food',\n",
       " 'for',\n",
       " 'force',\n",
       " 'ford',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000 post',\n",
       " '04 brian_snowflake',\n",
       " '04 brian_snowflake 300x225',\n",
       " '04 brian_snowflake 300x225 jpg',\n",
       " '1 2',\n",
       " '2013 04',\n",
       " '2013 04 brian_snowflake',\n",
       " '2013 04 brian_snowflake 300x225',\n",
       " '2013 04 brian_snowflake 300x225 jpg',\n",
       " '3 i',\n",
       " '3 years',\n",
       " '300x225 jpg',\n",
       " '358 or',\n",
       " '5am i',\n",
       " 'a better',\n",
       " 'a big',\n",
       " 'a bit',\n",
       " 'a bit of',\n",
       " 'a break',\n",
       " 'a certain',\n",
       " 'a couple',\n",
       " 'a damn',\n",
       " 'a fan',\n",
       " 'a fan of',\n",
       " 'a few',\n",
       " 'a few psychologist',\n",
       " 'a friend',\n",
       " 'a good',\n",
       " 'a good one',\n",
       " 'a good one at',\n",
       " 'a good one at that',\n",
       " 'a great',\n",
       " 'a guy',\n",
       " 'a half',\n",
       " 'a little',\n",
       " 'a little bit',\n",
       " 'a long',\n",
       " 'a lot',\n",
       " 'a lot of',\n",
       " 'a lot of people',\n",
       " 'a lounge',\n",
       " 'a new',\n",
       " 'a part',\n",
       " 'a piece',\n",
       " 'a piece of',\n",
       " 'a relationship',\n",
       " 'a religion',\n",
       " 'a sociopath',\n",
       " 'a very',\n",
       " 'a video',\n",
       " 'a waste',\n",
       " 'a waste of',\n",
       " 'a while',\n",
       " 'a year',\n",
       " 'ability to',\n",
       " 'able to',\n",
       " 'about a',\n",
       " 'about how',\n",
       " 'about it',\n",
       " 'about the',\n",
       " 'about this',\n",
       " 'advice i',\n",
       " 'agree that',\n",
       " 'ahh yes',\n",
       " 'albums zz96',\n",
       " 'albums zz96 kamioo',\n",
       " 'all i',\n",
       " 'all of',\n",
       " 'all of us',\n",
       " 'all the',\n",
       " 'all the time',\n",
       " 'all these',\n",
       " 'all up',\n",
       " 'also use',\n",
       " 'always be',\n",
       " 'am loyal',\n",
       " 'am loyal to',\n",
       " 'am not',\n",
       " 'amuses me',\n",
       " 'an atheist',\n",
       " 'an entp',\n",
       " 'an entp when',\n",
       " 'an entp when you',\n",
       " 'an extrovert',\n",
       " 'an infj',\n",
       " 'an intj',\n",
       " 'and a',\n",
       " 'and a half',\n",
       " 'and always',\n",
       " 'and even',\n",
       " 'and everything',\n",
       " 'and feel',\n",
       " 'and has',\n",
       " 'and have',\n",
       " 'and i',\n",
       " 'and i don',\n",
       " 'and i don t',\n",
       " 'and i don t think',\n",
       " 'and i have',\n",
       " 'and i like',\n",
       " 'and i m',\n",
       " 'and i m not',\n",
       " 'and i wish',\n",
       " 'and if',\n",
       " 'and it',\n",
       " 'and most',\n",
       " 'and my',\n",
       " 'and not',\n",
       " 'and now',\n",
       " 'and one',\n",
       " 'and people',\n",
       " 'and so',\n",
       " 'and social',\n",
       " 'and sweet',\n",
       " 'and the',\n",
       " 'and then',\n",
       " 'and then the',\n",
       " 'and things',\n",
       " 'and this',\n",
       " 'and unicorn',\n",
       " 'and unicorn chimes',\n",
       " 'and was',\n",
       " 'and what',\n",
       " 'and what i',\n",
       " 'and when',\n",
       " 'and your',\n",
       " 'any current',\n",
       " 'appears to',\n",
       " 'appears to be',\n",
       " 'appreciate the',\n",
       " 'are a',\n",
       " 'are just',\n",
       " 'are saying',\n",
       " 'are so',\n",
       " 'are the',\n",
       " 'are the same',\n",
       " 'are trying',\n",
       " 'are you',\n",
       " 'are your',\n",
       " 'area and',\n",
       " 'aren t',\n",
       " 'as a',\n",
       " 'as an',\n",
       " 'as i',\n",
       " 'as i m',\n",
       " 'as long',\n",
       " 'as long as',\n",
       " 'as much',\n",
       " 'as much as',\n",
       " 'as though',\n",
       " 'as we',\n",
       " 'as well',\n",
       " 'as you',\n",
       " 'as you can',\n",
       " 'ashton vern',\n",
       " 'asked me',\n",
       " 'asked me to',\n",
       " 'asked me to say',\n",
       " 'asked me to say goodnight',\n",
       " 'at least',\n",
       " 'at my',\n",
       " 'at people',\n",
       " 'at that',\n",
       " 'at the',\n",
       " 'at this',\n",
       " 'at this point',\n",
       " 'at times',\n",
       " 'at your',\n",
       " 'attempt to',\n",
       " 'aware of',\n",
       " 'away from',\n",
       " 'back at',\n",
       " 'back at this',\n",
       " 'back to',\n",
       " 'back to being',\n",
       " 'backed by',\n",
       " 'banned because',\n",
       " 'banned for',\n",
       " 'basis of',\n",
       " 'be a',\n",
       " 'be able',\n",
       " 'be able to',\n",
       " 'be an',\n",
       " 'be around',\n",
       " 'be good',\n",
       " 'be in',\n",
       " 'be like',\n",
       " 'be more',\n",
       " 'be so',\n",
       " 'be so damn',\n",
       " 'be the',\n",
       " 'be very',\n",
       " 'became a',\n",
       " 'because i',\n",
       " 'because most',\n",
       " 'because of',\n",
       " 'because the',\n",
       " 'because they',\n",
       " 'because you',\n",
       " 'been a',\n",
       " 'been the',\n",
       " 'before that',\n",
       " 'before that i',\n",
       " 'being an',\n",
       " 'being social',\n",
       " 'believe it',\n",
       " 'best friend',\n",
       " 'better than',\n",
       " 'bit of',\n",
       " 'both entps',\n",
       " 'brian_snowflake 300x225',\n",
       " 'brian_snowflake 300x225 jpg',\n",
       " 'bs i',\n",
       " 'but every',\n",
       " 'but every now',\n",
       " 'but every now and',\n",
       " 'but i',\n",
       " 'but i don',\n",
       " 'but i don t',\n",
       " 'but i m',\n",
       " 'but i would',\n",
       " 'but it',\n",
       " 'but it s',\n",
       " 'but more',\n",
       " 'but not',\n",
       " 'but that',\n",
       " 'but that s',\n",
       " 'but the',\n",
       " 'but they',\n",
       " 'but when',\n",
       " 'but when i',\n",
       " 'by that',\n",
       " 'by the',\n",
       " 'c i',\n",
       " 'camp online',\n",
       " 'camp online watch',\n",
       " 'camp online watch movies',\n",
       " 'camp online watch movies online',\n",
       " 'can be',\n",
       " 'can be very',\n",
       " 'can i',\n",
       " 'can t',\n",
       " 'can tell',\n",
       " 'care for',\n",
       " 'cms wp',\n",
       " 'cms wp content',\n",
       " 'cms wp content uploads',\n",
       " 'cms wp content uploads 2013',\n",
       " 'cognitive functions',\n",
       " 'com 2012',\n",
       " 'com albums',\n",
       " 'com albums zz96',\n",
       " 'com albums zz96 kamioo',\n",
       " 'com cms',\n",
       " 'com cms wp',\n",
       " 'com cms wp content',\n",
       " 'com cms wp content uploads',\n",
       " 'com watch',\n",
       " 'com watch v',\n",
       " 'com watch v cu8qsc1wlie',\n",
       " 'com wp',\n",
       " 'com wp content',\n",
       " 'com wp content uploads',\n",
       " 'come to',\n",
       " 'come up',\n",
       " 'come up with',\n",
       " 'comes to',\n",
       " 'comics about',\n",
       " 'common sense',\n",
       " 'content uploads',\n",
       " 'content uploads 2013',\n",
       " 'content uploads 2013 04',\n",
       " 'content uploads 2013 04 brian_snowflake',\n",
       " 'could be',\n",
       " 'course it',\n",
       " 'crush on',\n",
       " 'd be',\n",
       " 'd i',\n",
       " 'd i m',\n",
       " 'd say',\n",
       " 'day https',\n",
       " 'day https www',\n",
       " 'day https www youtube',\n",
       " 'day https www youtube com',\n",
       " 'deal to',\n",
       " 'deal with',\n",
       " 'definitely not',\n",
       " 'depends on',\n",
       " 'desktop that',\n",
       " 'desktop that i',\n",
       " 'did they',\n",
       " 'did you',\n",
       " 'didn t',\n",
       " 'didn t have',\n",
       " 'didn t know',\n",
       " 'do i',\n",
       " 'do i text',\n",
       " 'do i text her',\n",
       " 'do i text her or',\n",
       " 'do it',\n",
       " 'do not',\n",
       " 'do so',\n",
       " 'do that',\n",
       " 'do you',\n",
       " 'do you mean',\n",
       " 'do you think',\n",
       " 'doesn t',\n",
       " 'doesn t necessarily',\n",
       " 'doing it',\n",
       " 'doing what',\n",
       " 'don t',\n",
       " 'don t know',\n",
       " 'don t like',\n",
       " 'don t mean',\n",
       " 'don t think',\n",
       " 'don t think that',\n",
       " 'don t think you',\n",
       " 'done a',\n",
       " 'done by',\n",
       " 'dozens of',\n",
       " 'duck duck',\n",
       " 'due to',\n",
       " 'e i',\n",
       " 'each other',\n",
       " 'either 358',\n",
       " 'either 358 or',\n",
       " 'emotional connection',\n",
       " 'end up',\n",
       " 'entp when',\n",
       " 'entp when you',\n",
       " 'entps i',\n",
       " 'even if',\n",
       " 'every now',\n",
       " 'every now and',\n",
       " 'everything in',\n",
       " 'everything that',\n",
       " 'fall into',\n",
       " 'fan of',\n",
       " 'far i',\n",
       " 'favorite video',\n",
       " 'favorite video games',\n",
       " 'feel as',\n",
       " 'feel as though',\n",
       " 'feel fine',\n",
       " 'feel fine nothing',\n",
       " 'feel like',\n",
       " 'feel like i',\n",
       " 'few psychologist',\n",
       " 'fine nothing',\n",
       " 'first person',\n",
       " 'first person shooter',\n",
       " 'fleeting i',\n",
       " 'followed by',\n",
       " 'for a',\n",
       " 'for being',\n",
       " 'for example',\n",
       " 'for i',\n",
       " 'for it',\n",
       " 'for just',\n",
       " 'for me',\n",
       " 'for my',\n",
       " 'for sure',\n",
       " 'for the',\n",
       " 'for this',\n",
       " 'for us',\n",
       " 'for what',\n",
       " 'for you',\n",
       " 'from a',\n",
       " 'from my',\n",
       " 'from my apollo',\n",
       " 'from the',\n",
       " 'full movies',\n",
       " 'gain their',\n",
       " 'get i',\n",
       " 'get it',\n",
       " 'get to',\n",
       " 'give you',\n",
       " 'glad you',\n",
       " 'go on',\n",
       " 'god i',\n",
       " 'god i m',\n",
       " 'going back',\n",
       " 'going back to',\n",
       " 'going on',\n",
       " 'going to',\n",
       " 'going to be',\n",
       " 'going to take',\n",
       " 'good at',\n",
       " 'good night',\n",
       " 'good one',\n",
       " 'good one at',\n",
       " 'good one at that',\n",
       " 'good people',\n",
       " 'good question',\n",
       " 'good vs',\n",
       " 'good vs evil',\n",
       " 'goodnight to',\n",
       " 'goodnight to her',\n",
       " 'gordon and',\n",
       " 'gordon and unicorn',\n",
       " 'gordon and unicorn chimes',\n",
       " 'got the',\n",
       " 'great song',\n",
       " 'guy i',\n",
       " 'had a',\n",
       " 'had good',\n",
       " 'hard to',\n",
       " 'has been',\n",
       " 'have a',\n",
       " 'have an',\n",
       " 'have been',\n",
       " 'have my',\n",
       " 'have such',\n",
       " 'have to',\n",
       " 'have to ask',\n",
       " 'have you',\n",
       " 'haven t',\n",
       " 'having a',\n",
       " 'he has',\n",
       " 'he loves',\n",
       " 'he s',\n",
       " 'he was',\n",
       " 'help you',\n",
       " 'her as',\n",
       " 'her boss',\n",
       " 'her or',\n",
       " 'her or not',\n",
       " 'her or not do',\n",
       " 'her or not do i',\n",
       " 'here i',\n",
       " 'here you',\n",
       " 'here you go',\n",
       " 'high school',\n",
       " 'him to',\n",
       " 'hope they',\n",
       " 'how do',\n",
       " 'how do you',\n",
       " 'how i',\n",
       " 'how it',\n",
       " 'how many',\n",
       " 'how to',\n",
       " 'however i',\n",
       " 'http i817',\n",
       " 'http i817 photobucket',\n",
       " 'http i817 photobucket com',\n",
       " 'http i817 photobucket com albums',\n",
       " 'http www',\n",
       " 'http www penciltribe',\n",
       " 'http www penciltribe com',\n",
       " 'http www penciltribe com cms',\n",
       " 'http www youtube',\n",
       " 'http www youtube com',\n",
       " 'http www youtube com watch',\n",
       " 'http youtu',\n",
       " 'http youtu be',\n",
       " 'https www',\n",
       " 'https www youtube',\n",
       " 'https www youtube com',\n",
       " 'https www youtube com watch',\n",
       " 'human race',\n",
       " 'i actually',\n",
       " 'i agree',\n",
       " 'i agree that',\n",
       " 'i also',\n",
       " 'i am',\n",
       " 'i am loyal',\n",
       " 'i am loyal to',\n",
       " 'i am not',\n",
       " 'i believe',\n",
       " 'i can',\n",
       " 'i can be',\n",
       " 'i can tell',\n",
       " 'i cannot',\n",
       " 'i cant',\n",
       " 'i could',\n",
       " 'i d',\n",
       " 'i d be',\n",
       " 'i d say',\n",
       " 'i did',\n",
       " 'i didn',\n",
       " 'i didn t',\n",
       " 'i do',\n",
       " 'i do not',\n",
       " 'i don',\n",
       " 'i don t',\n",
       " 'i don t know',\n",
       " 'i don t like',\n",
       " 'i don t mean',\n",
       " 'i don t think',\n",
       " 'i don t think that',\n",
       " 'i don t think you',\n",
       " 'i doubt',\n",
       " 'i drank',\n",
       " 'i enjoyed',\n",
       " 'i feel',\n",
       " 'i feel as',\n",
       " 'i feel as though',\n",
       " 'i feel fine',\n",
       " 'i feel fine nothing',\n",
       " 'i find',\n",
       " 'i get',\n",
       " 'i go',\n",
       " 'i got',\n",
       " 'i guess',\n",
       " 'i had',\n",
       " 'i had a',\n",
       " 'i have',\n",
       " 'i have a',\n",
       " 'i have been',\n",
       " 'i have to',\n",
       " 'i haven',\n",
       " 'i haven t',\n",
       " 'i hope',\n",
       " 'i hope they',\n",
       " 'i i',\n",
       " 'i just',\n",
       " 'i know',\n",
       " 'i like',\n",
       " 'i like this',\n",
       " 'i like to',\n",
       " 'i ll',\n",
       " 'i ll take',\n",
       " 'i look',\n",
       " 'i love',\n",
       " 'i m',\n",
       " 'i m a',\n",
       " 'i m an',\n",
       " 'i m going',\n",
       " 'i m going to',\n",
       " 'i m in',\n",
       " 'i m in a',\n",
       " 'i m just',\n",
       " 'i m not',\n",
       " 'i m not a',\n",
       " 'i m not saying',\n",
       " 'i m still',\n",
       " 'i m working',\n",
       " 'i never',\n",
       " 'i normally',\n",
       " 'i really',\n",
       " 'i saw',\n",
       " 'i score',\n",
       " 'i see',\n",
       " 'i started',\n",
       " 'i started to',\n",
       " 'i still',\n",
       " 'i suggest',\n",
       " 'i tell',\n",
       " 'i tend',\n",
       " 'i tend to',\n",
       " 'i text',\n",
       " 'i text her',\n",
       " 'i text her or',\n",
       " 'i text her or not',\n",
       " 'i think',\n",
       " 'i think its',\n",
       " 'i think the',\n",
       " 'i think this',\n",
       " 'i thought',\n",
       " 'i use',\n",
       " 'i ve',\n",
       " 'i ve been',\n",
       " 'i ve come',\n",
       " 'i ve come to',\n",
       " 'i ve ever',\n",
       " 'i ve learned',\n",
       " 'i ve never',\n",
       " 'i want',\n",
       " 'i want to',\n",
       " 'i was',\n",
       " 'i was a',\n",
       " 'i will',\n",
       " 'i wish',\n",
       " 'i wish i',\n",
       " 'i would',\n",
       " 'i would have',\n",
       " 'i would say',\n",
       " 'i would say i',\n",
       " 'i wouldn',\n",
       " 'i wouldn t',\n",
       " 'i wouldn t be',\n",
       " 'i817 photobucket',\n",
       " 'i817 photobucket com',\n",
       " 'i817 photobucket com albums',\n",
       " 'i817 photobucket com albums zz96',\n",
       " 'idea of',\n",
       " 'idea that',\n",
       " 'identify with',\n",
       " 'if i',\n",
       " 'if it',\n",
       " 'if it s',\n",
       " 'if people',\n",
       " 'if she',\n",
       " 'if so',\n",
       " 'if the',\n",
       " 'if they',\n",
       " 'if this',\n",
       " 'if we',\n",
       " 'if you',\n",
       " 'if you ve',\n",
       " 'if you ve already',\n",
       " 'im not',\n",
       " 'impossible to',\n",
       " 'in a',\n",
       " 'in an',\n",
       " 'in backyard',\n",
       " 'in between',\n",
       " 'in depth',\n",
       " 'in every',\n",
       " 'in high',\n",
       " 'in high school',\n",
       " 'in moderation',\n",
       " 'in my',\n",
       " 'in my life',\n",
       " 'in my room',\n",
       " 'in our',\n",
       " 'in real',\n",
       " 'in real life',\n",
       " 'in some',\n",
       " 'in some ways',\n",
       " 'in terms',\n",
       " 'in terms of',\n",
       " 'in that',\n",
       " 'in the',\n",
       " 'in the middle',\n",
       " 'in this',\n",
       " 'in your',\n",
       " 'infj because',\n",
       " 'infj friend',\n",
       " 'infp i',\n",
       " 'intended to',\n",
       " 'interesting to',\n",
       " 'into a',\n",
       " 'intps are',\n",
       " 'iq test',\n",
       " 'is a',\n",
       " 'is all',\n",
       " 'is an',\n",
       " 'is going',\n",
       " 'is going to',\n",
       " 'is going to be',\n",
       " 'is hard',\n",
       " 'is in',\n",
       " 'is interesting',\n",
       " 'is it',\n",
       " 'is like',\n",
       " 'is more',\n",
       " 'is not',\n",
       " 'is nothing',\n",
       " 'is required',\n",
       " 'is so',\n",
       " 'is somewhat',\n",
       " 'is that',\n",
       " 'is the',\n",
       " 'is the first',\n",
       " 'is this',\n",
       " 'is to',\n",
       " 'is when',\n",
       " 'is why',\n",
       " 'is why i',\n",
       " 'it all',\n",
       " 'it and',\n",
       " 'it as',\n",
       " 'it can',\n",
       " 'it comes',\n",
       " 'it comes to',\n",
       " 'it for',\n",
       " 'it for me',\n",
       " 'it has',\n",
       " 'it i',\n",
       " 'it in',\n",
       " 'it is',\n",
       " 'it is not',\n",
       " 'it just',\n",
       " 'it makes',\n",
       " 'it makes me',\n",
       " 'it never',\n",
       " 'it s',\n",
       " 'it s a',\n",
       " 'it s like',\n",
       " 'it s more',\n",
       " 'it s not',\n",
       " 'it that',\n",
       " 'it that said',\n",
       " 'it that said i',\n",
       " 'it was',\n",
       " 'it was a',\n",
       " 'it wasn',\n",
       " 'it wasn t',\n",
       " 'it worked',\n",
       " 'it would',\n",
       " 'it would be',\n",
       " 'its been',\n",
       " 'jesus camp',\n",
       " 'jesus camp online',\n",
       " 'jesus camp online watch',\n",
       " 'jesus camp online watch movies',\n",
       " 'jpg http',\n",
       " 'just a',\n",
       " 'just as',\n",
       " 'just because',\n",
       " 'just enjoy',\n",
       " 'just my',\n",
       " 'keep me',\n",
       " 'kind of',\n",
       " 'know if',\n",
       " 'know me',\n",
       " 'know that',\n",
       " 'know what',\n",
       " 'know you',\n",
       " 'know you re',\n",
       " 'know you re an',\n",
       " 'know you re an entp',\n",
       " 'kokoro connect',\n",
       " 'lack of',\n",
       " 'leaning toward',\n",
       " 'learn to',\n",
       " 'left to',\n",
       " 'lelouch did',\n",
       " 'let s',\n",
       " 'life and',\n",
       " 'life i',\n",
       " 'life i m',\n",
       " 'like a',\n",
       " 'like an',\n",
       " 'like i',\n",
       " 'like i m',\n",
       " 'like it',\n",
       " 'like me',\n",
       " 'like my',\n",
       " 'like the',\n",
       " 'like this',\n",
       " 'like to',\n",
       " 'like to be',\n",
       " 'like when',\n",
       " 'like when you',\n",
       " 'like you',\n",
       " 'listen to',\n",
       " 'listen to me',\n",
       " 'little bit',\n",
       " 'll take',\n",
       " 'long as',\n",
       " 'long term',\n",
       " 'long time',\n",
       " 'look at',\n",
       " 'look at the',\n",
       " 'lot of',\n",
       " 'lot of people',\n",
       " 'low at',\n",
       " 'loyal to',\n",
       " 'm a',\n",
       " 'm an',\n",
       " 'm going',\n",
       " 'm going to',\n",
       " 'm in',\n",
       " 'm in a',\n",
       " 'm just',\n",
       " 'm not',\n",
       " 'm not a',\n",
       " 'm not saying',\n",
       " 'm still',\n",
       " 'm working',\n",
       " 'machine head',\n",
       " 'made up',\n",
       " 'make me',\n",
       " 'make you',\n",
       " 'make you a',\n",
       " 'makes me',\n",
       " 'managed to',\n",
       " 'may be',\n",
       " 'may have',\n",
       " 'may have been',\n",
       " 'may not',\n",
       " 'me a',\n",
       " 'me and',\n",
       " 'me better',\n",
       " 'me but',\n",
       " 'me for',\n",
       " 'me i',\n",
       " 'me is',\n",
       " 'me it',\n",
       " 'me the',\n",
       " 'me the most',\n",
       " 'me to',\n",
       " 'me to say',\n",
       " 'me to say goodnight',\n",
       " 'me to say goodnight to',\n",
       " 'me which',\n",
       " 'me with',\n",
       " 'mean by',\n",
       " 'mental health',\n",
       " 'methods disturbing',\n",
       " 'mind just',\n",
       " 'mind that',\n",
       " 'mode i',\n",
       " 'more i',\n",
       " 'more important',\n",
       " 'more than',\n",
       " 'most efficient',\n",
       " 'most of',\n",
       " 'most of the',\n",
       " 'most of them',\n",
       " 'movies online',\n",
       " 'movies online full',\n",
       " 'movies online full movies',\n",
       " 'much as',\n",
       " 'much of',\n",
       " 'much to',\n",
       " 'my answer',\n",
       " 'my apollo',\n",
       " 'my best',\n",
       " 'my desktop',\n",
       " 'my desktop that',\n",
       " 'my desktop that i',\n",
       " 'my favourite',\n",
       " 'my feelings',\n",
       " 'my friends',\n",
       " 'my gay',\n",
       " 'my infj',\n",
       " 'my infj friend',\n",
       " 'my laundry',\n",
       " 'my life',\n",
       " 'my life i',\n",
       " 'my mouth',\n",
       " 'my own',\n",
       " 'my point',\n",
       " 'my previous',\n",
       " 'my previous post',\n",
       " 'my room',\n",
       " 'my so',\n",
       " 'my time',\n",
       " 'my type',\n",
       " 'myself to',\n",
       " 'myself with',\n",
       " 'name of',\n",
       " 'need a',\n",
       " 'need to',\n",
       " 'need to be',\n",
       " 'need to know',\n",
       " 'never had',\n",
       " 'never really',\n",
       " 'next day',\n",
       " 'no i',\n",
       " 'no matter',\n",
       " 'nope nope',\n",
       " 'not a',\n",
       " 'not all',\n",
       " 'not an',\n",
       " 'not be',\n",
       " 'not do',\n",
       " 'not do i',\n",
       " 'not do i text',\n",
       " 'not do i text her',\n",
       " 'not find',\n",
       " 'not her',\n",
       " 'not like',\n",
       " 'not saying',\n",
       " 'not sure',\n",
       " 'not the',\n",
       " 'not there',\n",
       " 'not to',\n",
       " 'not too',\n",
       " 'not trying',\n",
       " 'not trying to',\n",
       " 'not very',\n",
       " 'nothing to',\n",
       " 'now and',\n",
       " 'now i',\n",
       " 'now that',\n",
       " 'number 1',\n",
       " 'of a',\n",
       " 'of all',\n",
       " 'of all of',\n",
       " 'of any',\n",
       " 'of as',\n",
       " 'of attraction',\n",
       " 'of being',\n",
       " 'of course',\n",
       " 'of course it',\n",
       " 'of god',\n",
       " 'of it',\n",
       " 'of me',\n",
       " 'of music',\n",
       " 'of my',\n",
       " 'of my time',\n",
       " 'of ni',\n",
       " 'of our',\n",
       " 'of people',\n",
       " 'of religion',\n",
       " 'of the',\n",
       " 'of the universe',\n",
       " 'of the universe and',\n",
       " 'of the universe and the',\n",
       " 'of their',\n",
       " 'of them',\n",
       " 'of things',\n",
       " 'of this',\n",
       " 'of this thread',\n",
       " 'of time',\n",
       " 'of us',\n",
       " 'of years',\n",
       " 'of you',\n",
       " 'of your',\n",
       " 'off i',\n",
       " 'oh i',\n",
       " 'oh my',\n",
       " 'on a',\n",
       " 'on i',\n",
       " 'on me',\n",
       " 'on my',\n",
       " 'on my desktop',\n",
       " 'on my desktop that',\n",
       " 'on my desktop that i',\n",
       " 'on the',\n",
       " 'on their',\n",
       " 'on this',\n",
       " 'on what',\n",
       " 'on your',\n",
       " 'one another',\n",
       " 'one at',\n",
       " 'one at that',\n",
       " 'one do',\n",
       " 'one is',\n",
       " 'one of',\n",
       " 'one of my',\n",
       " 'one of the',\n",
       " 'online full',\n",
       " 'online full movies',\n",
       " 'online watch',\n",
       " 'online watch movies',\n",
       " 'online watch movies online',\n",
       " 'online watch movies online full',\n",
       " 'only to',\n",
       " 'only with',\n",
       " 'op being',\n",
       " 'or a',\n",
       " 'or all',\n",
       " 'or not',\n",
       " 'or not do',\n",
       " 'or not do i',\n",
       " 'or not do i text',\n",
       " 'or red',\n",
       " 'or sometimes',\n",
       " 'orphan black',\n",
       " 'other people',\n",
       " 'other people s',\n",
       " 'other than',\n",
       " 'other than that',\n",
       " 'other types',\n",
       " 'out of',\n",
       " 'out there',\n",
       " 'out with',\n",
       " 'over a',\n",
       " 'own nails',\n",
       " 'part of',\n",
       " 'penciltribe com',\n",
       " 'penciltribe com cms',\n",
       " 'penciltribe com cms wp',\n",
       " 'penciltribe com cms wp content',\n",
       " 'people are',\n",
       " 'people i',\n",
       " 'people just',\n",
       " 'people like',\n",
       " 'people need',\n",
       " 'people need to',\n",
       " 'people s',\n",
       " 'people s expectations',\n",
       " 'people to',\n",
       " 'people who',\n",
       " 'perhaps you',\n",
       " 'person shooter',\n",
       " 'photobucket com',\n",
       " 'photobucket com albums',\n",
       " 'photobucket com albums zz96',\n",
       " 'photobucket com albums zz96 kamioo',\n",
       " 'piece of',\n",
       " 'plan is',\n",
       " 'plan is horrifying',\n",
       " 'plan is horrifying if',\n",
       " 'plan is horrifying if tomorrow',\n",
       " 'planet is',\n",
       " 'planet is somewhat',\n",
       " 'planet is somewhat silly',\n",
       " 'planet is somewhat silly even',\n",
       " 'planet which',\n",
       " 'planet which sounds',\n",
       " 'planet which sounds rare',\n",
       " 'planet which sounds rare when',\n",
       " 'planets cosmic',\n",
       " 'planets cosmic nah',\n",
       " 'planets cosmic nah 1',\n",
       " 'planets cosmic nah 1 since',\n",
       " 'planning a',\n",
       " 'planning a murder',\n",
       " 'planning a murder in',\n",
       " 'planning a murder in my',\n",
       " 'plans i',\n",
       " 'plans i have',\n",
       " 'plans i have for',\n",
       " 'plans i have for you',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_ngram.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usage of any word2vec, its format of 300 dimension and 1st element as word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999994\n",
      ",\n",
      "the\n",
      ".\n",
      "and\n",
      "of\n",
      "to\n",
      "in\n",
      "a\n",
      "\"\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('wiki-news-300d-1M.vec', encoding=\"utf8\")):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "    print(values[0])\n",
    "    if i==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'the': 2,\n",
       " 'to': 3,\n",
       " 'a': 4,\n",
       " 'and': 5,\n",
       " 'of': 6,\n",
       " 'you': 7,\n",
       " 'it': 8,\n",
       " 'in': 9,\n",
       " 'is': 10,\n",
       " 'that': 11,\n",
       " 'my': 12,\n",
       " 'be': 13,\n",
       " 'with': 14,\n",
       " 'this': 15,\n",
       " 'for': 16,\n",
       " 'com': 17,\n",
       " 'not': 18,\n",
       " 'on': 19,\n",
       " 'are': 20,\n",
       " 'have': 21,\n",
       " 'me': 22,\n",
       " \"i'm\": 23,\n",
       " 'like': 24,\n",
       " 'as': 25,\n",
       " 'was': 26,\n",
       " 'watch': 27,\n",
       " 'or': 28,\n",
       " 'what': 29,\n",
       " 'but': 30,\n",
       " 'so': 31,\n",
       " 'www': 32,\n",
       " 'do': 33,\n",
       " 'youtube': 34,\n",
       " 'v': 35,\n",
       " 'just': 36,\n",
       " 'if': 37,\n",
       " 'http': 38,\n",
       " 'your': 39,\n",
       " 'can': 40,\n",
       " 'an': 41,\n",
       " \"don't\": 42,\n",
       " 'think': 43,\n",
       " 'when': 44,\n",
       " 'people': 45,\n",
       " 'at': 46,\n",
       " 'all': 47,\n",
       " 'would': 48,\n",
       " 'we': 49,\n",
       " 'more': 50,\n",
       " 'they': 51,\n",
       " 'one': 52,\n",
       " 'about': 53,\n",
       " 'most': 54,\n",
       " 'up': 55,\n",
       " 'by': 56,\n",
       " 'from': 57,\n",
       " 'time': 58,\n",
       " 'good': 59,\n",
       " 'things': 60,\n",
       " 'know': 61,\n",
       " 'because': 62,\n",
       " 'how': 63,\n",
       " 'them': 64,\n",
       " 'https': 65,\n",
       " \"it's\": 66,\n",
       " 'there': 67,\n",
       " \"i've\": 68,\n",
       " 'her': 69,\n",
       " 'now': 70,\n",
       " 'then': 71,\n",
       " 'get': 72,\n",
       " 'being': 73,\n",
       " 'than': 74,\n",
       " 'out': 75,\n",
       " 'other': 76,\n",
       " 'will': 77,\n",
       " 'am': 78,\n",
       " 'their': 79,\n",
       " 'who': 80,\n",
       " 'say': 81,\n",
       " 'been': 82,\n",
       " 'too': 83,\n",
       " 'even': 84,\n",
       " 'no': 85,\n",
       " 'feel': 86,\n",
       " 'life': 87,\n",
       " 'only': 88,\n",
       " 'type': 89,\n",
       " 'want': 90,\n",
       " 'really': 91,\n",
       " 'much': 92,\n",
       " 'very': 93,\n",
       " 'which': 94,\n",
       " 'see': 95,\n",
       " 'though': 96,\n",
       " 'he': 97,\n",
       " 'some': 98,\n",
       " \"you're\": 99,\n",
       " 'way': 100,\n",
       " 'these': 101,\n",
       " 'go': 102,\n",
       " 'going': 103,\n",
       " 'our': 104,\n",
       " 'thought': 105,\n",
       " 'into': 106,\n",
       " 'right': 107,\n",
       " 'still': 108,\n",
       " 'sometimes': 109,\n",
       " 'why': 110,\n",
       " 'she': 111,\n",
       " 'actually': 112,\n",
       " 'has': 113,\n",
       " 'use': 114,\n",
       " 'could': 115,\n",
       " 'd': 116,\n",
       " \"that's\": 117,\n",
       " 'never': 118,\n",
       " 'also': 119,\n",
       " 'back': 120,\n",
       " 'had': 121,\n",
       " 'need': 122,\n",
       " 'were': 123,\n",
       " 'always': 124,\n",
       " 'person': 125,\n",
       " 'love': 126,\n",
       " 'said': 127,\n",
       " 'those': 128,\n",
       " 'intj': 129,\n",
       " 'thing': 130,\n",
       " 'while': 131,\n",
       " 'any': 132,\n",
       " 'well': 133,\n",
       " '2': 134,\n",
       " 'many': 135,\n",
       " 'two': 136,\n",
       " 'myself': 137,\n",
       " 'look': 138,\n",
       " 'long': 139,\n",
       " 'infp': 140,\n",
       " 'make': 141,\n",
       " 'yes': 142,\n",
       " 'here': 143,\n",
       " 'same': 144,\n",
       " 'social': 145,\n",
       " '1': 146,\n",
       " 'over': 147,\n",
       " 'first': 148,\n",
       " 'its': 149,\n",
       " 'everything': 150,\n",
       " 'someone': 151,\n",
       " 'nothing': 152,\n",
       " 'own': 153,\n",
       " 'thoughts': 154,\n",
       " 'him': 155,\n",
       " 'best': 156,\n",
       " 'did': 157,\n",
       " 'anything': 158,\n",
       " 'such': 159,\n",
       " 'lot': 160,\n",
       " 'god': 161,\n",
       " 'jpg': 162,\n",
       " 'may': 163,\n",
       " 'every': 164,\n",
       " 'hard': 165,\n",
       " 'each': 166,\n",
       " 'types': 167,\n",
       " 'old': 168,\n",
       " 'real': 169,\n",
       " 'year': 170,\n",
       " 'find': 171,\n",
       " 'makes': 172,\n",
       " 'lol': 173,\n",
       " \"i'll\": 174,\n",
       " 'off': 175,\n",
       " 'seem': 176,\n",
       " 'infj': 177,\n",
       " 'friend': 178,\n",
       " 'times': 179,\n",
       " 'mean': 180,\n",
       " 'everyone': 181,\n",
       " 'few': 182,\n",
       " 'years': 183,\n",
       " 'better': 184,\n",
       " 'new': 185,\n",
       " 'where': 186,\n",
       " 'us': 187,\n",
       " 'post': 188,\n",
       " 'saying': 189,\n",
       " 'great': 190,\n",
       " 'oh': 191,\n",
       " 'friends': 192,\n",
       " 'tell': 193,\n",
       " 'until': 194,\n",
       " \"doesn't\": 195,\n",
       " 'sense': 196,\n",
       " 'feeling': 197,\n",
       " 'fi': 198,\n",
       " 'done': 199,\n",
       " 'point': 200,\n",
       " 'his': 201,\n",
       " 'before': 202,\n",
       " \"i'd\": 203,\n",
       " 'around': 204,\n",
       " 'entp': 205,\n",
       " 'part': 206,\n",
       " '3': 207,\n",
       " 'idea': 208,\n",
       " \"'\": 209,\n",
       " 'words': 210,\n",
       " 'perhaps': 211,\n",
       " 'ti': 212,\n",
       " 'after': 213,\n",
       " 'both': 214,\n",
       " 'photobucket': 215,\n",
       " 'albums': 216,\n",
       " \"didn't\": 217,\n",
       " 'through': 218,\n",
       " 'trying': 219,\n",
       " 'take': 220,\n",
       " 'help': 221,\n",
       " 'bad': 222,\n",
       " 'infjs': 223,\n",
       " 'work': 224,\n",
       " 'does': 225,\n",
       " 'probably': 226,\n",
       " 'night': 227,\n",
       " 'doing': 228,\n",
       " 'interesting': 229,\n",
       " 'either': 230,\n",
       " 'sure': 231,\n",
       " 'got': 232,\n",
       " 'mbti': 233,\n",
       " 'religion': 234,\n",
       " 'tumblr': 235,\n",
       " 'day': 236,\n",
       " 'try': 237,\n",
       " 'content': 238,\n",
       " 'maybe': 239,\n",
       " 'banned': 240,\n",
       " 'thread': 241,\n",
       " 'something': 242,\n",
       " 'music': 243,\n",
       " \"he's\": 244,\n",
       " 'often': 245,\n",
       " 'score': 246,\n",
       " 'i817': 247,\n",
       " 'zz96': 248,\n",
       " 'kamioo': 249,\n",
       " 'deal': 250,\n",
       " 'bit': 251,\n",
       " 'between': 252,\n",
       " 'damn': 253,\n",
       " 'give': 254,\n",
       " 'intjs': 255,\n",
       " 'down': 256,\n",
       " 'quite': 257,\n",
       " 'another': 258,\n",
       " 'op': 259,\n",
       " 'edit': 260,\n",
       " 'certain': 261,\n",
       " 'last': 262,\n",
       " 'least': 263,\n",
       " 'come': 264,\n",
       " 'world': 265,\n",
       " 'live': 266,\n",
       " 'high': 267,\n",
       " 'taking': 268,\n",
       " 'posts': 269,\n",
       " 'believe': 270,\n",
       " 'happens': 271,\n",
       " 'guys': 272,\n",
       " 'png': 273,\n",
       " 'sounds': 274,\n",
       " 'little': 275,\n",
       " 'intps': 276,\n",
       " 'ones': 277,\n",
       " 'able': 278,\n",
       " 'made': 279,\n",
       " 'course': 280,\n",
       " 'read': 281,\n",
       " 'head': 282,\n",
       " 'hope': 283,\n",
       " 'understand': 284,\n",
       " 'impossible': 285,\n",
       " 'show': 286,\n",
       " 'others': 287,\n",
       " 'emotional': 288,\n",
       " 'happy': 289,\n",
       " 'whatever': 290,\n",
       " 'question': 291,\n",
       " 'vs': 292,\n",
       " 'evil': 293,\n",
       " 'since': 294,\n",
       " 'text': 295,\n",
       " 'experience': 296,\n",
       " 'hear': 297,\n",
       " 'relationship': 298,\n",
       " 'stuff': 299,\n",
       " 'red': 300,\n",
       " 'given': 301,\n",
       " 'left': 302,\n",
       " 'somewhat': 303,\n",
       " 'personality': 304,\n",
       " 'followed': 305,\n",
       " 'movies': 306,\n",
       " 'whole': 307,\n",
       " 'room': 308,\n",
       " 'kind': 309,\n",
       " 'position': 310,\n",
       " 'big': 311,\n",
       " 'test': 312,\n",
       " 'ne': 313,\n",
       " 'ni': 314,\n",
       " 'put': 315,\n",
       " 'entps': 316,\n",
       " 'song': 317,\n",
       " 'close': 318,\n",
       " 'called': 319,\n",
       " 'hurt': 320,\n",
       " \"wasn't\": 321,\n",
       " 'later': 322,\n",
       " 'feelings': 323,\n",
       " 'mind': 324,\n",
       " 'intp': 325,\n",
       " 'human': 326,\n",
       " 'should': 327,\n",
       " 'started': 328,\n",
       " 'change': 329,\n",
       " 'online': 330,\n",
       " 'conversation': 331,\n",
       " 'wish': 332,\n",
       " 'fine': 333,\n",
       " 'talk': 334,\n",
       " 'mostly': 335,\n",
       " 'went': 336,\n",
       " 'having': 337,\n",
       " 'thinking': 338,\n",
       " 'full': 339,\n",
       " 'tv': 340,\n",
       " 'tend': 341,\n",
       " 'general': 342,\n",
       " 'media': 343,\n",
       " 'posted': 344,\n",
       " 'next': 345,\n",
       " 'wp': 346,\n",
       " 'uploads': 347,\n",
       " 'round': 348,\n",
       " 'game': 349,\n",
       " 'video': 350,\n",
       " 'dear': 351,\n",
       " 'favorite': 352,\n",
       " 'current': 353,\n",
       " 'sad': 354,\n",
       " 'enjoy': 355,\n",
       " 'sentence': 356,\n",
       " 'watching': 357,\n",
       " 'class': 358,\n",
       " 'clearly': 359,\n",
       " '20': 360,\n",
       " 'self': 361,\n",
       " 'under': 362,\n",
       " 'ago': 363,\n",
       " 'example': 364,\n",
       " 'enough': 365,\n",
       " 'internet': 366,\n",
       " 'rather': 367,\n",
       " 'fe': 368,\n",
       " 'playing': 369,\n",
       " 'couple': 370,\n",
       " 'heart': 371,\n",
       " 'mental': 372,\n",
       " 'movie': 373,\n",
       " 'except': 374,\n",
       " 'guy': 375,\n",
       " 'personal': 376,\n",
       " 'pretty': 377,\n",
       " 'place': 378,\n",
       " 'seems': 379,\n",
       " 'already': 380,\n",
       " 'however': 381,\n",
       " 'weird': 382,\n",
       " 'themselves': 383,\n",
       " 'mine': 384,\n",
       " \"wouldn't\": 385,\n",
       " 'yourself': 386,\n",
       " 'awesome': 387,\n",
       " 'absolutely': 388,\n",
       " 'feels': 389,\n",
       " 'ever': 390,\n",
       " 'beautiful': 391,\n",
       " 'doubt': 392,\n",
       " 'songs': 393,\n",
       " 'together': 394,\n",
       " 'interested': 395,\n",
       " 'works': 396,\n",
       " 'sleep': 397,\n",
       " 'anyway': 398,\n",
       " 'finally': 399,\n",
       " 'problems': 400,\n",
       " 'important': 401,\n",
       " 'entj': 402,\n",
       " 'ways': 403,\n",
       " 'depends': 404,\n",
       " 'esfj': 405,\n",
       " 'similar': 406,\n",
       " 'previous': 407,\n",
       " 'definitely': 408,\n",
       " 'te': 409,\n",
       " 'dark': 410,\n",
       " 'reading': 411,\n",
       " 'far': 412,\n",
       " 'appreciate': 413,\n",
       " 'common': 414,\n",
       " 'once': 415,\n",
       " 'depth': 416,\n",
       " 'answer': 417,\n",
       " 'saw': 418,\n",
       " 'agree': 419,\n",
       " 'wants': 420,\n",
       " 'dream': 421,\n",
       " 'cannot': 422,\n",
       " 'hands': 423,\n",
       " 'wrong': 424,\n",
       " 'end': 425,\n",
       " 'nice': 426,\n",
       " 'care': 427,\n",
       " 'required': 428,\n",
       " 'says': 429,\n",
       " 'haha': 430,\n",
       " 'whenever': 431,\n",
       " 'situation': 432,\n",
       " 'trauma': 433,\n",
       " 'dreams': 434,\n",
       " 'enfp': 435,\n",
       " 'today': 436,\n",
       " 'hello': 437,\n",
       " 'sorry': 438,\n",
       " 'moment': 439,\n",
       " 'girl': 440,\n",
       " '04': 441,\n",
       " 'welcome': 442,\n",
       " '2013': 443,\n",
       " 'pokemon': 444,\n",
       " 'sitting': 445,\n",
       " \"you've\": 446,\n",
       " 'likely': 447,\n",
       " 'functions': 448,\n",
       " 'late': 449,\n",
       " 'b': 450,\n",
       " 'health': 451,\n",
       " 'reasons': 452,\n",
       " 'middle': 453,\n",
       " 'using': 454,\n",
       " '2012': 455,\n",
       " 'didnt': 456,\n",
       " 'version': 457,\n",
       " 'artists': 458,\n",
       " 'learn': 459,\n",
       " 'share': 460,\n",
       " 'ahh': 461,\n",
       " 'school': 462,\n",
       " 'heard': 463,\n",
       " 'sort': 464,\n",
       " 'learned': 465,\n",
       " 'move': 466,\n",
       " 'area': 467,\n",
       " 'start': 468,\n",
       " 'sex': 469,\n",
       " 'boring': 470,\n",
       " 'girlfriend': 471,\n",
       " 'presence': 472,\n",
       " 'iq': 473,\n",
       " 'funny': 474,\n",
       " 'higher': 475,\n",
       " 'half': 476,\n",
       " 'sherlock': 477,\n",
       " 'man': 478,\n",
       " 'p': 479,\n",
       " 'dominates': 480,\n",
       " 'si': 481,\n",
       " 'due': 482,\n",
       " 'system': 483,\n",
       " 'hell': 484,\n",
       " 'sound': 485,\n",
       " 'aware': 486,\n",
       " \"won't\": 487,\n",
       " 'style': 488,\n",
       " 'beat': 489,\n",
       " 'extrovert': 490,\n",
       " 'normally': 491,\n",
       " 'gay': 492,\n",
       " 't': 493,\n",
       " 'perfect': 494,\n",
       " 'imagine': 495,\n",
       " 'trust': 496,\n",
       " 'usual': 497,\n",
       " 'duck': 498,\n",
       " 'knew': 499,\n",
       " 'play': 500,\n",
       " 'laugh': 501,\n",
       " 'psychologist': 502,\n",
       " '6': 503,\n",
       " 'stay': 504,\n",
       " '10': 505,\n",
       " '11': 506,\n",
       " 'suggest': 507,\n",
       " 'random': 508,\n",
       " 'thanks': 509,\n",
       " 'keep': 510,\n",
       " 'positive': 511,\n",
       " 'thank': 512,\n",
       " 'terrible': 513,\n",
       " 'peculiar': 514,\n",
       " 'different': 515,\n",
       " '30': 516,\n",
       " 'entire': 517,\n",
       " 'working': 518,\n",
       " 'book': 519,\n",
       " 'various': 520,\n",
       " 'mentioned': 521,\n",
       " 'hopefully': 522,\n",
       " 'sacrifice': 523,\n",
       " 'waste': 524,\n",
       " \"what's\": 525,\n",
       " 'precise': 526,\n",
       " 'basis': 527,\n",
       " 'visual': 528,\n",
       " 'must': 529,\n",
       " 'rule': 530,\n",
       " 'action': 531,\n",
       " 'means': 532,\n",
       " 'rarity': 533,\n",
       " 'awhile': 534,\n",
       " 'mother': 535,\n",
       " 'collect': 536,\n",
       " 'wow': 537,\n",
       " 'nobody': 538,\n",
       " 'u': 539,\n",
       " 'break': 540,\n",
       " 'comes': 541,\n",
       " 'yeah': 542,\n",
       " 'series': 543,\n",
       " 'useful': 544,\n",
       " 'normal': 545,\n",
       " 'process': 546,\n",
       " 'generally': 547,\n",
       " 'bother': 548,\n",
       " 'asked': 549,\n",
       " 'lives': 550,\n",
       " 'ass': 551,\n",
       " 'vacation': 552,\n",
       " 'boss': 553,\n",
       " 'listen': 554,\n",
       " 'efficient': 555,\n",
       " 'possible': 556,\n",
       " 'shut': 557,\n",
       " 'scenario': 558,\n",
       " 'petty': 559,\n",
       " 'xd': 560,\n",
       " 'understanding': 561,\n",
       " 'drink': 562,\n",
       " 'dry': 563,\n",
       " 'images': 564,\n",
       " 'q': 565,\n",
       " 'vision': 566,\n",
       " 'terms': 567,\n",
       " 'plenty': 568,\n",
       " 'goals': 569,\n",
       " 'term': 570,\n",
       " 'questions': 571,\n",
       " 'effective': 572,\n",
       " 'hate': 573,\n",
       " 'found': 574,\n",
       " 'methods': 575,\n",
       " 'although': 576,\n",
       " 'word': 577,\n",
       " 'connect': 578,\n",
       " 'let': 579,\n",
       " 'relate': 580,\n",
       " 'kill': 581,\n",
       " 'number': 582,\n",
       " 'seeing': 583,\n",
       " 'anyone': 584,\n",
       " 'plan': 585,\n",
       " 'geass': 586,\n",
       " 'learning': 587,\n",
       " 'realistic': 588,\n",
       " 'explain': 589,\n",
       " 'guess': 590,\n",
       " 'vote': 591,\n",
       " 'rob': 592,\n",
       " 'follow': 593,\n",
       " \"can't\": 594,\n",
       " 'nails': 595,\n",
       " 'physical': 596,\n",
       " 'comfort': 597,\n",
       " 'pay': 598,\n",
       " 'exact': 599,\n",
       " \"people's\": 600,\n",
       " 'became': 601,\n",
       " 'plans': 602,\n",
       " 'looks': 603,\n",
       " 'dreaming': 604,\n",
       " 'favourite': 605,\n",
       " 'im': 606,\n",
       " 'cant': 607,\n",
       " 'levels': 608,\n",
       " 'nope': 609,\n",
       " 'fleeting': 610,\n",
       " 'patience': 611,\n",
       " 'orphan': 612,\n",
       " 'black': 613,\n",
       " \"she's\": 614,\n",
       " 'changing': 615,\n",
       " 'perc': 616,\n",
       " 'facebook': 617,\n",
       " 'figure': 618,\n",
       " 'upload': 619,\n",
       " 'friendship': 620,\n",
       " 'design': 621,\n",
       " 'master': 622,\n",
       " 'moving': 623,\n",
       " 'legs': 624,\n",
       " 'moderation': 625,\n",
       " 'alternative': 626,\n",
       " 'whichever': 627,\n",
       " 'cognitive': 628,\n",
       " 'indeed': 629,\n",
       " 'subjective': 630,\n",
       " 'completely': 631,\n",
       " 'games': 632,\n",
       " 'cool': 633,\n",
       " 'appears': 634,\n",
       " \"there's\": 635,\n",
       " 'wait': 636,\n",
       " 'c': 637,\n",
       " 'within': 638,\n",
       " 'yo': 639,\n",
       " 'hey': 640,\n",
       " 'conversations': 641,\n",
       " 'quickly': 642,\n",
       " '50': 643,\n",
       " 'backyard': 644,\n",
       " 'kisses': 645,\n",
       " 'blood': 646,\n",
       " 'diary': 647,\n",
       " 'latest': 648,\n",
       " 'wall': 649,\n",
       " 'society': 650,\n",
       " 'becomes': 651,\n",
       " 'net': 652,\n",
       " 'draw': 653,\n",
       " 'signature': 654,\n",
       " 'herself': 655,\n",
       " 'proud': 656,\n",
       " 'bed': 657,\n",
       " 'gotta': 658,\n",
       " \"haven't\": 659,\n",
       " 'public': 660,\n",
       " 'speaking': 661,\n",
       " 'again': 662,\n",
       " 'lack': 663,\n",
       " 'currently': 664,\n",
       " 'meaning': 665,\n",
       " 'theory': 666,\n",
       " 'grin': 667,\n",
       " 'takes': 668,\n",
       " 'flirting': 669,\n",
       " 'return': 670,\n",
       " 'balance': 671,\n",
       " 'hand': 672,\n",
       " 'tests': 673,\n",
       " 'vanish': 674,\n",
       " 'liking': 675,\n",
       " 'ideas': 676,\n",
       " 'img188': 677,\n",
       " 'holmes': 678,\n",
       " 'quote': 679,\n",
       " 'special': 680,\n",
       " 'powers': 681,\n",
       " 'complex': 682,\n",
       " 'e': 683,\n",
       " 'j': 684,\n",
       " 'emotions': 685,\n",
       " 'rarely': 686,\n",
       " 'strength': 687,\n",
       " 'shooter': 688,\n",
       " 'rock': 689,\n",
       " 'equipment': 690,\n",
       " 'managed': 691,\n",
       " 'noticed': 692,\n",
       " 'mic': 693,\n",
       " 'away': 694,\n",
       " 'mouth': 695,\n",
       " 'ninja': 696,\n",
       " 'background': 697,\n",
       " 'sociable': 698,\n",
       " 'played': 699,\n",
       " 'books': 700,\n",
       " 'estj': 701,\n",
       " 'looked': 702,\n",
       " 'biggest': 703,\n",
       " 'female': 704,\n",
       " 'crush': 705,\n",
       " 'living': 706,\n",
       " 'worst': 707,\n",
       " 'dull': 708,\n",
       " 'turned': 709,\n",
       " 'leaning': 710,\n",
       " 'toward': 711,\n",
       " 'identify': 712,\n",
       " 'building': 713,\n",
       " 'car': 714,\n",
       " 'laughing': 715,\n",
       " 'meet': 716,\n",
       " 'lesbian': 717,\n",
       " 'advice': 718,\n",
       " 'build': 719,\n",
       " 'wake': 720,\n",
       " 'awake': 721,\n",
       " 'till': 722,\n",
       " 'opinion': 723,\n",
       " 'backed': 724,\n",
       " 'socially': 725,\n",
       " 'difficult': 726,\n",
       " 'situations': 727,\n",
       " 'desktop': 728,\n",
       " 'stock': 729,\n",
       " 'glad': 730,\n",
       " 'static': 731,\n",
       " 'several': 732,\n",
       " 'hours': 733,\n",
       " 'avatar': 734,\n",
       " 'diagnosis': 735,\n",
       " 'curse': 736,\n",
       " 'amazing': 737,\n",
       " 'count': 738,\n",
       " 'case': 739,\n",
       " 'topic': 740,\n",
       " 'dozens': 741,\n",
       " 'species': 742,\n",
       " 'faces': 743,\n",
       " '5': 744,\n",
       " 'incredibly': 745,\n",
       " 'whoever': 746,\n",
       " 'hi': 747,\n",
       " 'garden': 748,\n",
       " 'pm': 749,\n",
       " 'guitar': 750,\n",
       " 'seen': 751,\n",
       " 'felt': 752,\n",
       " 'comics': 753,\n",
       " 'turtle': 754,\n",
       " 'gordon': 755,\n",
       " 'unicorn': 756,\n",
       " 'chimes': 757,\n",
       " 'stories': 758,\n",
       " 'alexxxandra': 759,\n",
       " 'include': 760,\n",
       " 'upon': 761,\n",
       " 'nah': 762,\n",
       " 'touch': 763,\n",
       " 'thinks': 764,\n",
       " 'scared': 765,\n",
       " 'true': 766,\n",
       " 'fact': 767,\n",
       " 'face': 768,\n",
       " 'kitten': 769,\n",
       " 'hugs': 770,\n",
       " 'wishing': 771,\n",
       " 'name': 772,\n",
       " 'response': 773,\n",
       " 'helpful': 774,\n",
       " 'patterns': 775,\n",
       " 'food': 776,\n",
       " 'cares': 777,\n",
       " 'surrounding': 778,\n",
       " 'else': 779,\n",
       " 'anger': 780,\n",
       " 'chosen': 781,\n",
       " 'race': 782,\n",
       " 'ability': 783,\n",
       " 'worked': 784,\n",
       " 'thousands': 785,\n",
       " 'arts': 786,\n",
       " 'study': 787,\n",
       " 'badly': 788,\n",
       " 'istp': 789,\n",
       " 'enjoyed': 790,\n",
       " 'nature': 791,\n",
       " 'universe': 792,\n",
       " 'code': 793,\n",
       " 'arbitrary': 794,\n",
       " 'sub': 795,\n",
       " 'alpha': 796,\n",
       " 'scale': 797,\n",
       " '358': 798,\n",
       " 'distinction': 799,\n",
       " 'indicates': 800,\n",
       " 'primary': 801,\n",
       " 'personally': 802,\n",
       " 'interactions': 803,\n",
       " 'absolute': 804,\n",
       " 'refreshing': 805,\n",
       " 'disagree': 806,\n",
       " 'definite': 807,\n",
       " 'sick': 808,\n",
       " \"let's\": 809,\n",
       " 'necessarily': 810,\n",
       " 'equal': 811,\n",
       " 'lately': 812,\n",
       " 'longer': 813,\n",
       " 'whether': 814,\n",
       " 'fun': 815,\n",
       " 'compare': 816,\n",
       " 'belief': 817,\n",
       " 'relatively': 818,\n",
       " 'wanna': 819,\n",
       " 'ended': 820,\n",
       " 'cognition': 821,\n",
       " 'sx': 822,\n",
       " 'seriously': 823,\n",
       " 'interpret': 824,\n",
       " 'beyond': 825,\n",
       " 'analysis': 826,\n",
       " 'assume': 827,\n",
       " 'view': 828,\n",
       " 'explanation': 829,\n",
       " 'huh': 830,\n",
       " '5am': 831,\n",
       " 'wanted': 832,\n",
       " 'almost': 833,\n",
       " 'asking': 834,\n",
       " 'intuitive': 835,\n",
       " 'decided': 836,\n",
       " 'goodnight': 837,\n",
       " 'actual': 838,\n",
       " 'math': 839,\n",
       " 'literally': 840,\n",
       " 'numbers': 841,\n",
       " 'jobs': 842,\n",
       " 'planet': 843,\n",
       " 'silly': 844,\n",
       " 'potential': 845,\n",
       " 'logically': 846,\n",
       " 'entitled': 847,\n",
       " 'approached': 848,\n",
       " 'bs': 849,\n",
       " 'super': 850,\n",
       " 'months': 851,\n",
       " 'crazy': 852,\n",
       " 'reliable': 853,\n",
       " 'gone': 854,\n",
       " 'lost': 855,\n",
       " 'shit': 856,\n",
       " 'project': 857,\n",
       " 'gave': 858,\n",
       " 'woman': 859,\n",
       " 'piece': 860,\n",
       " 'youtu': 861,\n",
       " 'forum': 862,\n",
       " 'ask': 863,\n",
       " '25': 864,\n",
       " 'month': 865,\n",
       " 'making': 866,\n",
       " 'dead': 867,\n",
       " 'men': 868,\n",
       " \"aren't\": 869,\n",
       " 'brain': 870,\n",
       " 'value': 871,\n",
       " 'instead': 872,\n",
       " 'drank': 873,\n",
       " 'hardcore': 874,\n",
       " 'sweet': 875,\n",
       " 'wine': 876,\n",
       " 'interest': 877,\n",
       " 'loyal': 878,\n",
       " 'hitler': 879,\n",
       " 'concept': 880,\n",
       " 'effects': 881,\n",
       " 'dichotomy': 882,\n",
       " 'negative': 883,\n",
       " 'characteristics': 884,\n",
       " 'reason': 885,\n",
       " 'gain': 886,\n",
       " 'energy': 887,\n",
       " 'focus': 888,\n",
       " 'penciltribe': 889,\n",
       " 'cms': 890,\n",
       " 'brian': 891,\n",
       " 'snowflake': 892,\n",
       " '300x225': 893,\n",
       " 'written': 894,\n",
       " 'arguments': 895,\n",
       " 'acknowledging': 896,\n",
       " 'information': 897,\n",
       " 'obvious': 898,\n",
       " 'isfp': 899,\n",
       " 'flat': 900,\n",
       " 'disturbing': 901,\n",
       " 'bring': 902,\n",
       " 'control': 903,\n",
       " 'google': 904,\n",
       " 'jesus': 905,\n",
       " 'camp': 906,\n",
       " 'gun': 907,\n",
       " \"someone's\": 908,\n",
       " 'attraction': 909,\n",
       " 'dipped': 910,\n",
       " 'internally': 911,\n",
       " 'avoid': 912,\n",
       " 'truth': 913,\n",
       " 'telling': 914,\n",
       " 'anime': 915,\n",
       " 'kokoro': 916,\n",
       " 'looking': 917,\n",
       " 'told': 918,\n",
       " 'ground': 919,\n",
       " 'subjects': 920,\n",
       " 'destroying': 921,\n",
       " 'lose': 922,\n",
       " 'understands': 923,\n",
       " 'took': 924,\n",
       " 'become': 925,\n",
       " 'sociopath': 926,\n",
       " 'tells': 927,\n",
       " 'meeting': 928,\n",
       " 'attempt': 929,\n",
       " 'sympathy': 930,\n",
       " 'lelouch': 931,\n",
       " 'pick': 932,\n",
       " 'details': 933,\n",
       " 'fall': 934,\n",
       " 'along': 935,\n",
       " 'bothered': 936,\n",
       " 'recognize': 937,\n",
       " 'four': 938,\n",
       " 'grow': 939,\n",
       " 'pizza': 940,\n",
       " 'happen': 941,\n",
       " 'english': 942,\n",
       " 'degree': 943,\n",
       " 'intended': 944,\n",
       " 'f': 945,\n",
       " 'anxiety': 946,\n",
       " 'secure': 947,\n",
       " 'research': 948,\n",
       " 'simply': 949,\n",
       " 'atheists': 950,\n",
       " 'religious': 951,\n",
       " 'atheist': 952,\n",
       " 'apparently': 953,\n",
       " 'mafia': 954,\n",
       " 'writer': 955,\n",
       " 'isfj': 956,\n",
       " 'father': 957,\n",
       " 'sister': 958,\n",
       " 'side': 959,\n",
       " 'step': 960,\n",
       " 'brother': 961,\n",
       " 'esfp': 962,\n",
       " 'technology': 963,\n",
       " 'suffer': 964,\n",
       " 'past': 965,\n",
       " 'hearing': 966,\n",
       " 'future': 967,\n",
       " 'tongue': 968,\n",
       " 'values': 969,\n",
       " 'helps': 970,\n",
       " 'pull': 971,\n",
       " 'stand': 972,\n",
       " 'creating': 973,\n",
       " 'minds': 974,\n",
       " 'princess': 975,\n",
       " 'pls': 976,\n",
       " 'coming': 977,\n",
       " 'source': 978,\n",
       " 'psychopath': 979,\n",
       " 'wishes': 980,\n",
       " 'expectations': 981,\n",
       " 'ashton': 982,\n",
       " 'vern': 983,\n",
       " 'further': 984,\n",
       " 'loves': 985,\n",
       " 'white': 986,\n",
       " 'war': 987,\n",
       " 'mode': 988,\n",
       " 'happening': 989,\n",
       " 'lonely': 990,\n",
       " 'suddenly': 991,\n",
       " 'hrs': 992,\n",
       " 'paying': 993,\n",
       " 'attention': 994,\n",
       " 'anymore': 995,\n",
       " 'earlier': 996,\n",
       " 'catch': 997,\n",
       " 'outside': 998,\n",
       " 'lucid': 999,\n",
       " 'less': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0, ...,   27,   35, 1540])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('wiki-news-300d-1M.vec', encoding=\"utf8\")):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=2000)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=2000)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "trainDF['decimal_or_digit_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isdecimal() or wrd.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day.\"), Sentence(\"Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7.\"), Sentence(\"Sorry to hear of your distress.\"), Sentence(\"It's only natural for a relationship to not be perfection all the time in every moment of existence.\"), Sentence(\"Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game.\"), Sentence(\"Set.\"), Sentence(\"Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.\"), Sentence(\"Sims is indeed a video game, and a good one at that.\"), Sentence(\"Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games?\"), Sentence(\":cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late.\"), Sentence(\":sad:|||There's someone out there for everyone.|||Wait...\"), Sentence(\"I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can.\"), Sentence(\"Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence.\"), Sentence(\"How could you!\"), Sentence(\"Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.\"), Sentence(\"2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.\"), Sentence(\"3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw.\"), Sentence(\"It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself.\"), Sentence(\":proud:|||Banned for taking all the room under my bed.\"), Sentence(\"Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.\"), Sentence(\"http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again.\"), Sentence(\"A big part of my failure was just overloading myself with too...|||I like this person's mentality.\"), Sentence(\"He's a confirmed INTJ by the way.\"), Sentence(\"http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\")]\n",
      "[Sentence(\"'I'm finding the lack of me in these posts very alarming.|||Sex can be boring if it's in the same position often.\"), Sentence(\"For example me and my girlfriend are currently in an environment where we have to creatively use cowgirl and missionary.\"), Sentence(\"There isn't enough...|||Giving new meaning to 'Game' theory.|||Hello *ENTP Grin*  That's all it takes.\"), Sentence(\"Than we converse and they do most of the flirting while I acknowledge their presence and return their words with smooth wordplay and more cheeky grins.|||This + Lack of Balance and Hand Eye Coordination.|||Real IQ test I score 127.\"), Sentence(\"Internet IQ tests are funny.\"), Sentence(\"I score 140s or higher.\"), Sentence(\"Now, like the former responses of this thread I will mention that I don't believe in the IQ test.\"), Sentence(\"Before you banish...|||You know you're an ENTP when you vanish from a site for a year and a half, return, and find people are still commenting on your posts and liking your ideas/thoughts.\"), Sentence(\"You know you're an ENTP when you...|||http://img188.imageshack.us/img188/6422/6020d1f9da6944a6b71bbe6.jpg|||http://img.adultdvdtalk.com/813a0c6243814cab84c51|||I over think things sometimes.\"), Sentence(\"I go by the old Sherlock Holmes quote.\"), Sentence(\"Perhaps, when a man has special knowledge and special powers like my  own, it rather encourages him to seek a complex...|||cheshirewolf.tumblr.com  So is I :D|||400,000+  post|||Not really; I've never thought of E/I or J/P as real functions.\"), Sentence(\"I judge myself on what I use.\"), Sentence(\"I use Ne and Ti as my dominates.\"), Sentence(\"Fe for emotions and rarely Si.\"), Sentence(\"I also use Ni due to me strength...|||You know though.\"), Sentence(\"That was ingenious.\"), Sentence(\"After saying it I really want to try it and see what happens with me playing a first person shooter in the back while we drive around.\"), Sentence(\"I want to see the look on...|||out of all of them the rock paper one is the best.\"), Sentence(\"It makes me lol.\"), Sentence(\"You guys are lucky :D I'm really high up on the tumblr system.|||So did you hear about that new first person shooter game?\"), Sentence(\"I've been rocking the hell out of the soundtrack on my auto sound equipment that will shake the heavens.\"), Sentence(\"We managed to put a couple PS3's in...|||No; The way he connected things was very Ne.\"), Sentence(\"Ne dominates are just as aware of their environments as Se dominates.\"), Sentence(\"Example: Shawn Spencer or Patrick Jane; Both ENTPs.|||Well charlie I will be the first to admit I do get jealous like you do.\"), Sentence(\"I chalk it up to my 4w3 heart mixed with my dominate 7w8.\"), Sentence(\"7s and 8s both like to be noticed.\"), Sentence(\"4's like to be known (not the same...|||;D I'll upload the same clip with the mic away from my mouth.\"), Sentence(\"Than you won't hear anything.\"), Sentence(\"Ninja Assassin style but with splatter.|||Tik Tok is a really great song.\"), Sentence(\"As long as you can mental block out the singer.\"), Sentence(\"I love the beat it makes me bounce.|||drop.io v1swck0  :D Mic really close to my mouth and smokin aces: assassins ball playing in the background.|||Sociable =/= extrovert; I'm an extrovert and I'm not sociable.\"), Sentence(\":)|||Sherlock in the movie was an ENTP.\"), Sentence(\"Normally he's played as a EXTJ.\"), Sentence(\"In the books he's an ESTJ.\"), Sentence(\"As I said.\"), Sentence(\"The movie looked good except for it being called sherlock holmes.|||http://i817.photobucket.com/albums/zz96/kamioo/Dirtywinch.png|||Oh, I never had fear of kissing a guy.\"), Sentence(\"I will kiss an animal too.\"), Sentence(\"So there was nothing to vanish.\"), Sentence(\"Just personal taste and me not liking it.\"), Sentence(\"The guy I kissed didn't know me.\"), Sentence(\"It was one of those...|||Sounds pretty much like my area and what I'm going through right now trying to figure out which way I want to take my life.\"), Sentence(\"I want to do so many things.\"), Sentence(\"The biggest problem is that I know if I don't...|||;D I was operating under the impression that you were female.\"), Sentence(\"I never looked at your boxy.\"), Sentence(\"Okay, I help out my gay friends all the time and one of them has developed a little crush on me.\"), Sentence(\"I get red...|||T_T You just described me  and I'm living the worst nightmare.\"), Sentence(\"I'm trapped in one place with one one around.\"), Sentence(\"Only dull woods.\"), Sentence(\"If I was a serial killer this would be the perfect place but sadly I'm...|||TBH, and biased, sounds like a shadowed INFP.\"), Sentence(\"I think maybe he was hurt and turned ESTJ.\"), Sentence(\"I can tell because he has some of the typical INFP traits left over.|||*Checks list* I'm sorry.\"), Sentence(\"It seems that you have came at a bad time.\"), Sentence(\"We've already reached our quota of INFJs.\"), Sentence(\"However, being you're female and I like females I will make you a deal.\"), Sentence(\"I will kick one...|||I'm ANTP (Leaning toward E).\"), Sentence(\"I'm easy for both ENTPs and INTPs to identify with.\"), Sentence(\":)|||I also imagine ENTP's interrogations would go a little bit like Jack's from 24 except more mechanical.\"), Sentence(\"Rigging up shock treatment equipment in an abandoned building out of an old car batty, jumper...|||It was a compliment :) Trust me.\"), Sentence(\"I'm just as psychopathic :D except I have emoticons.\"), Sentence(\"They're just weird ones.\"), Sentence(\"Like laughing when I get hurt or at people running themselves over with their lawn mower...|||http://i817.photobucket.com/albums/zz96/kamioo/Thunderstorm.pnghttp://i817.photobucket.com/albums/zz96/kamioo/Thunderstormbw.png http://i817.photobucket.com/albums/zz96/kamioo/Cosmicstorm.png|||No.\"), Sentence(\"It's like a theme for where I live and that is why I know it by heart.\"), Sentence(\"http://www.youtube.com/watch?v=j5W73HaVQBg|||and I usual don't leave until the thing ends.\"), Sentence(\"But in the mean time.\"), Sentence(\"In between times.\"), Sentence(\"You work your thing.\"), Sentence(\"I'll work mine :D  ;D I'm the MBP; Pleasure to meet you.|||Damn, need to trust my instincts more I would have been closer I was going to say INFP.|||EXFP?\"), Sentence(\"Leaning toward S with the way she responded.\"), Sentence(\":D My friends, even my gay and lesbian ones, always come to me for advice.|||I bow to my entp masters ENTPs are so great.\"), Sentence(\"If it wasn't for ENTPs I wouldn't have been able to build what I'm building  Duck Duck  Duck  Shotgun|||What?\"), Sentence(\"Me?\"), Sentence(\"I never do that >.> <.<|||Because its hard to be sad about losing someone you like when you knew you were right and give yourself a big pat on the back because you're awesome and always correct.|||Oh, you don't have to tell me that most of them are stupid.\"), Sentence(\"I know this.\"), Sentence(\"That is why I play with them and it makes me laugh.\"), Sentence(\":D As I'm going to take Neuropsychology and I have a few psychologist...|||:D I'm a Nightowl.\"), Sentence(\"I wake up between 6-7pm and stay awake till 10-11:30am.|||Personal opinion backed by theory would suggest that INTPs are the most socially difficult.\"), Sentence(\"While INTJs can be socially indifferent but they will also use social situations if the the need arises....|||Personal stocks that I have on my desktop that I've downloaded from random stock sites and stock photobuckets.|||I'll tell you when I open photoshop.\"), Sentence(\":) Glad you like it static.|||:D Thanks.|||http://i817.photobucket.com/albums/zz96/kamioo/Deathgrip.png http://i817.photobucket.com/albums/zz96/kamioo/Deathgripbw.png  Made for a friend.\"), Sentence(\"Several hours of work.\"), Sentence(\"I constructed every line by...|||:) Static: http://i817.photobucket.com/albums/zz96/kamioo/Statickitten.png  I'll have to get to your avatar later if one of my fellow teammates doesn't.|||Psychologist don't keep me around long enough to diagnosis me.\"), Sentence(\"I like to toy with them.\"), Sentence(\"What I have diagnosis myself with and had a few psychologist friends (+ a few other friends) tell me I have is...'\")]\n",
      "[Sentence(\"'Good one  _____   https://www.youtube.com/watch?v=fHiGbolFFGw|||Of course, to which I say I know; that's my blessing and my curse.|||Does being absolutely positive that you and your best friend could be an amazing couple count?\"), Sentence(\"If so, than yes.\"), Sentence(\"Or it's more I could be madly in love in case I reconciled my feelings (which at...|||No, I didn't; thank you for a link!|||So-called Ti-Si loop (and it can stem from any current topic/obsession) can be deadly.\"), Sentence(\"It's like when you're stuck in your own thoughts, and your mind just wanders in circles.\"), Sentence(\"Feels truly terrible.\"), Sentence(\"...|||Have you noticed how peculiar vegetation can be?\"), Sentence(\"All you have to do is look down at the grass: dozens of different plant species there.\"), Sentence(\"And now imagine that hundreds of years later (when/if soil...|||The Smiths  Never Had No One Ever|||I often find myself spotting faces on marble tiles/wood.|||This 5 year-old sentence is an incredibly accurate and beautiful description.|||I haven't visited this website in the last 3 years.\"), Sentence(\"So whoever reads this (and maybe even remembers me, which I highly doubt): hi.\"), Sentence(\"700049  700057|||When you sit in your garden until 10:30 PM writing songs, and sing them (together with dozens of crickets) while playing your acoustic guitar.|||This is the most INTP-ish thread I've ever seen.|||I wouldn't be able to look at the painting for the entire life if I knew that I picked it over the human being.|||I was drawing a background for my animation on which I'm working right now - it should have been Mars..\"), Sentence(\"But I felt obligated to make Mark Watneyx92s postcard from it :D  If you read the book...|||I started to make comics about turtle Gordon and unicorn Chimes - here you can see two first stories: https://www.tumblr.com/blog/-alexxxandra-|||INTJ Recently I started to post my comics about two friends - turtle Gordon and unicorn Chimes.\"), Sentence(\"Before that, I just posted stuff that interested me, but from now on I'll try to include only my works...|||Probably we could work together on a new model - I'm an expert in abrupt explosions of laughter upon various weird stuff.\"), Sentence(\"That happens because of peculiar sense of humor - so peculiar that not much...|||Hellooo Nah, you can touch it.\"), Sentence(\"Everyone thinks that it's scared or sad, but that's not true - in fact it has an absolutely neutral face.\"), Sentence(\"And this kitten actually really likes patting and hugs (only...|||Well.. kind of; As it was already mentioned, sometimes because of Ni it's hard to convey complex stuff which pops up in your head in whimsical compilations of shapes and pictures only with words....|||I think this kitten would be very appropriate here.\"), Sentence(\"376562|||367034|||GOOD NIGHT everyone out there!\"), Sentence(\"Even if for someone there is morning right now - nights always supersede mornings.. And people say good night in order to meet next day :)|||Oh, that movie :) It's awesome Thank you!\"), Sentence(\"Hope you had good sleep in the air; anyway, I'm wishing you good night for the next night ahead!\"), Sentence(\"(hopefully it will be on land)  Good people deserve good...|||358882  358890|||Well, other people who may be wondering about an issue from the name of the topic will find your response helpful anyway :)|||This.\"), Sentence(\"Finally someone mentioned that :)|||I still see creatures/faces in a maze of various random patterns.\"), Sentence(\"It can be amusing sometimes.\"), Sentence(\"It's a very handy skill when you're bored.|||Oh, I didn't know that.. What a pity.\"), Sentence(\"Why not sacrifice whole supermarket, then?\"), Sentence(\"We can decide which Walmart will be the best (I think the biggest one would be great).|||yippy  Here you go  357002  He thinks that the fire is delicious.\"), Sentence(\"Should I sacrifice tofu?\"), Sentence(\"I don't like to waste food.|||I don't think that the creator of this thread cares what's going on here after 3 years :)|||Heh, I understand you :) With these same given languages)))|||Yessss, Adventure Time :D|||I get angry quite rarely, but when I do, it's safer for surrounding people to go somewhere else.\"), Sentence(\"It's impossible for me to hide or suppress anger; the only way to get rid of this feeling is to burst...|||I've never liked it  Anything fake is bad, actually.|||Hugs should be given only to chosen ones.\"), Sentence(\"Chosen.\"), Sentence(\"There are quite few of them, though.|||349890|||Yup, you're doing it right :)|||http://-alexxxandra-.tumblr.com/|||256818|||Of course it's not very comfortable.\"), Sentence(\"But.\"), Sentence(\"Human race survived thankfully women's ability to give birth to other human beings.\"), Sentence(\"It worked for thousands of years.\"), Sentence(\"Why change it?\"), Sentence(\"Besides, there are...|||That happens.\"), Sentence(\"And it occurs because most often people use results of extremely precise and elaborate online tests as a basis of determining one's type.\"), Sentence(\"Both visual and language arts (more...|||246386|||I study graphic design now, which I really enjoy.\"), Sentence(\"What is interesting about this field, is that the ability to generate ideas and solve problems is much more important than possession of a specific...|||Alexxxandra97 - DeviantArt|||236994|||http://www.youtube.com/watch?v=2Nkcn8m9M0M|||I am always ready to discipline (to intimidate, to be precise) my sibling's offender.|||World domination?\"), Sentence(\"Shooting people in the head?\"), Sentence(\"Why?\"), Sentence(\"Oh, right, INTJs always must be characterised only with these words.\"), Sentence(\"I want to show so badly my reaction to this: 221226|||218106|||ISTP?\"), Sentence(\"http://www.youtube.com/watch?v=7ghqoYxmaUE'\")]\n",
      "[Sentence(\"'Dear INTP,   I enjoyed our conversation the other day.\"), Sentence(\"Esoteric gabbing about the nature of the universe and the idea that every rule and social code being arbitrary constructs created...|||Dear ENTJ sub,   Long time no see.\"), Sentence(\"Sincerely, Alpha|||None of them.\"), Sentence(\"All other types hurt in deep existential ways that I want no part of.|||Probably a sliding scale that depends on individual preferences, like everything in humanity.|||Draco Malfoy also.\"), Sentence(\"I'd say he's either 358 or 368.|||I'm either 358 or 385, though in which stacking to me is a somewhat arbitrary distinction to make as I believe that the core indicates primary motivation and has a hand in every action.\"), Sentence(\"Therefore, a...|||I'm not particularly introverted or extraverted, personally.\"), Sentence(\"That said, I would say I'm somewhat unphased by either social interactions or being alone.\"), Sentence(\"What I'd say I crave more so than anything is...|||Dear Type 9 INFP,  Your absolute admiration of me is refreshing.\"), Sentence(\"You're a great girlfriend and I wish we both didn't have such busy schedules so we could be around one another more often.\"), Sentence(\"Keep...|||2% still means about 1/50 people.\"), Sentence(\"I've probably seen 1-2 others today.\"), Sentence(\"I never understood fascination by virtue of rarity.|||So, you're on the ESFJ train also, right?|||I have toyed with the idea of the OP being an extrovert also for awhile now, actually.\"), Sentence(\"After many conversations with him, however I'm disinclined to believe it due to OP being much too close with Fi...|||Still ESFJ|||I disagree.\"), Sentence(\"Definite ESFJ.\"), Sentence(\"Fe- Si ALL up in this.|||Where have you been?\"), Sentence(\"Your mother and I have been worried sick.|||Similar feelings concerning ENTPs.|||I collect shoes.\"), Sentence(\"I do so because I like status and nothing communicates such a thing as much as a pair of Jordans.|||Sure.\"), Sentence(\"Let's get weird.\"), Sentence(\"Back.\"), Sentence(\"Off.|||Best...|||[Insert other into previous post.\"), Sentence(\"]|||Wow, don't nobody got time fo' dat...  Jk, u kno u mah boi.|||Well, as I'm sure everyone knows, being social primary doesn't necessarily equal being social.\"), Sentence(\"I like other people just fine, but lately I've been on a bit of a break when it comes to my...|||That's pretty crappy of her.\"), Sentence(\"Your sex life is definitely not her business.\"), Sentence(\"If I were you, I'd definitely talk to her about it.|||Yeah, I had a lot longer to think about it.\"), Sentence(\"That said, I don't think you're Te, so if we operate under the assumptions in the OP, you're INFJ because nothing else makes sense.\"), Sentence(\"I'm not saying I...|||Whether or not you actually are, your mom makes fun of you for being a virgin?\"), Sentence(\"Is this playful teasing?|||Just stab in the dark here, I don't think that's Te under the hood.\"), Sentence(\"If this here is all I'm given to work with, I'd have to say INFJ.\"), Sentence(\"Compare your idea of 'logic' to mine:  Logic is a series of...|||What makes the most sense?|||Tentatively INTJ.\"), Sentence(\"Still reading.\"), Sentence(\"EDIT: So far, I am of the belief that you're most of the things you say you are.\"), Sentence(\"I appreciate the level of detail.\"), Sentence(\"EDIT: Also relatively certain you are Ni...|||Refreshing self with reading about instinctual variants.\"), Sentence(\"God, I'm a hard social type.|||WOW!\"), Sentence(\"Useful thought you had there!\"), Sentence(\"Wanna know what my favorite part was?\"), Sentence(\"The fact that it ended...|||I am both annoyed and intrigued by xxFPs.\"), Sentence(\"As far as I can tell, I dislike all J types in my normal life.|||I'm not of the mind that any enneatype/MBTI combination is impossible because cognition =/= the things that motivate us.\"), Sentence(\"That said, we can clearly observe many types being more common than others...|||Sx as hell...   https://www.youtube.com/watch?v=uelHwf8o7_U|||Very seriously toying with the idea of being 351.\"), Sentence(\"I can be pretty aggressive and controlling, but I have a massive 'holier than thou' streak once you get to know me with any depth (like more than 1-2...|||I'd say it's a mostly emotional experience.|||Because I find in depth study of cognition more interesting.\"), Sentence(\"Included MBTI in my answer to illustrate how much I enjoyed socionics.\"), Sentence(\"Interpret the post as wholehearted agreement with what she was...|||No real argument here.\"), Sentence(\"I know what I am, and what I am is an asshole that is, for a second baring his teeth at the people that seemingly have a lot to say but refuse to address me beyond a single...|||I would refer you to the OP.\"), Sentence(\"If you need a literal analysis, I'm happy to provide it.\"), Sentence(\"That said, I'm going to assume you're able to read and interpret symbolism, so I doubt you'll need that much help.|||And this was sort of my thought process.\"), Sentence(\"The initial post and how it connects the generally accepted view of the type 3 and what the type 3 is motivated by doesn't seem to be in need of explanation....|||Oh my...\"), Sentence(\"I am quite crushable, huh?\"), Sentence(\"Back atcha.|||I was, but it's 5am.\"), Sentence(\"I'll take what I can get.|||I wanted to come up with something clever, but it's almost 5am.\"), Sentence(\"I would give you a lot of sex.|||So then why do you even bother asking if you've already made up your mind that you are an extravert, intuitive and feeling?\"), Sentence(\"If you've  already decided you are these things and have evidently done the...|||Wasn't sure I listened to sx music until now.\"), Sentence(\"https://www.youtube.com/watch?v=7hcYx_y5xdo|||INFP messaged me with a picture of herself before going to bed.\"), Sentence(\"Asked me to say goodnight to her.\"), Sentence(\"Asked me to say goodnight to her again.\"), Sentence(\"I did.\"), Sentence(\"I thought it was weird, secretly.\"), Sentence(\"I like...|||Either way, you see my point.\"), Sentence(\"The actual rarity is skewed and makes a type seem rarer than it likely is in real contexts.\"), Sentence(\"I may have been the only one of my type in a class room in High School, but...|||WOW my math was off!\"), Sentence(\"I literally just said numbers.\"), Sentence(\"See how over glorified the type is?\"), Sentence(\"Even so, though.\"), Sentence(\"I saw around two-hundred people (REALLY rough estimate) between both of my jobs.\"), Sentence(\"It's...|||Rarity in the context of the entire planet is somewhat silly.\"), Sentence(\"Even if we assume the greatest reports of our 'rarity', we (INTJ) encompass 1% of the planet, which sounds rare when you don't think...|||One could say that whatever the culmination of all of our actions are throughout our lives equal our potential.\"), Sentence(\"In this sense, everybody does, but as we all know, not everyone's potential is the...|||I would agree, however, those that profess to know their type not stating anything about their type's motivations strike me as either not wanting to touch on them or not being able to.\"), Sentence(\"If they don't...|||Lol.'\")]\n",
      "[Sentence(\"'You're fired.|||That's another silly misconception.\"), Sentence(\"That approaching is logically is going to be the key to unlocking whatever it is you think you are entitled to.\"), Sentence(\"Nobody wants to be approached with BS...|||But guys... he REALLY wants to go on a super-duper-long-ass vacation.\"), Sentence(\"C'mon guys.\"), Sentence(\"His boss just doesn't listen or get it.\"), Sentence(\"He even approached him logically and everything.|||Never mind.\"), Sentence(\"Just go on permanent vacation.|||Two months?\"), Sentence(\"I wouldn't be crazy about the idea.\"), Sentence(\"If you are really his best employee, then that's what may be cooking him.\"), Sentence(\"Who wants their most reliable asset gone for that long?\"), Sentence(\"ENTJ employer...|||Lol.\"), Sentence(\"Its not like our views were unsolicited.\"), Sentence(\"What a victim.|||Sometimes I just really like impoverished rap music.\"), Sentence(\"https://www.youtube.com/watch?v=Xh0vA6_8mv8|||I probably would have lost it too.\"), Sentence(\"His stonewalling was insignificant.\"), Sentence(\"He was being an idiot over semantics that didn't have any impact on anything.\"), Sentence(\"It's one thing to stone wall on critical shit, but...|||I would have just taken the project and gave them something later.|||The court deposition wasn't a skit.\"), Sentence(\"That actually happened.\"), Sentence(\"It was a verbatim reenactment.|||And her ass.|||I'll flirt a woman for a piece of candy at the grocery store.\"), Sentence(\"Of course.\"), Sentence(\"I use whatever I have at my disposal to get what I want in the most efficient manner possible.\"), Sentence(\"If that means flirting that...|||http://youtu.be/PZbqAMEwtOE|||Yes.\"), Sentence(\"In the comments she gave more info, then was shut down because she went from having a crush on her boss and wanted to know how to impress him, to her boss is married and she wasn't interested.\"), Sentence(\"I...|||What's this we thing about?|||Callaendia are you the same INFP girl who was on the ENTJ Facebook forum with this similar question?\"), Sentence(\"I just have to ask because the times are so close together, and the scenario is so similar.|||3X|||11/25 I do not modify myself to suit others, however I do like the spotlight.|||I think the easiest and most efficient approach is a tarp, jigsaw, and mulcher.\"), Sentence(\"But that's just my personal preference.\"), Sentence(\"Not all ENTJs are the same.|||Just don't hump my leg...|||What are you like a chihuahua or some shit?|||I once dumped a girl in college who I was having a 6 month romp with over making me late for class.\"), Sentence(\"She said I was petty for it.|||DEAD XD   http://youtu.be/PaghIdSJKvQ|||MBTIPC perfect.\"), Sentence(\"I don't like dealing with middle men either.\"), Sentence(\"You can talk directly to me.\"), Sentence(\";)|||I can sell you the dream...|||LOL DEAD.\"), Sentence(\"Ha!|||The point is that when you are making a point of thinking critically but not thinking beyond common sense, you aren't using your brain.\"), Sentence(\"A little bit of effort now to have an understanding of the...|||That's just common sense  No, that's just a value judgement backed by popular opinion from social stupidity/laziness.\"), Sentence(\"That's only doing what works instead of pushing harder and doing what is...|||When it comes to children, they either cry or climb all over me.\"), Sentence(\"There is never a gray area.|||I don't drink, but when I drank:  Beer: Hardcore ciders and sweet brown ales.\"), Sentence(\"Liquor: VODKA chased with cran or water.\"), Sentence(\"< my preferred drink  Wine: Anything dark, dry and sweet.\"), Sentence(\"There are so...|||Well that escalated quickly.|||https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcSDA-GNSWRqDgxZibQPN3dfS2LlChp8tO6FCCeVBHuIlYUVfjzkVH2sGAv_  You deal with them.|||tl;dr fuuuuu|||Those people who think they know everything are a great annoyance to those of us who do IA|||@Darth Alpha  I would never claim it to be healthy either.\"), Sentence(\"Just in my best interest.|||On loyalty:  I am loyal to the vision.\"), Sentence(\"I am loyal to those who share the vision.\"), Sentence(\"I am not into co-dependency in terms of the vision cannot be accomplished without others involved.\"), Sentence(\"I stay on course,...|||Your answer was worth more time to entertain than the OP.|||Hey @MsBossyPants are you down for a debate on Ayn Rand vs Marx?\"), Sentence(\"Maybe we should talk about our poor Fi?\"), Sentence(\"Oh I know- let's try to correlate testing ENTJ with being sociopathic.\"), Sentence(\":laughing:|||Hitler was no exception- this concept has, is and always will be a principle, tenet, and rule.\"), Sentence(\"Politics, ideology, religion, eating, shitting usual.\"), Sentence(\"And if it's not ,then there is nothing to...|||Hitler thought he was doing great things.\"), Sentence(\"Stalin thought he was justified.\"), Sentence(\"These guys thought they were uncorrupt.\"), Sentence(\"They viewed any heretic to their dogmas as morally bankrupt, and so did many of...|||Meh.\"), Sentence(\"There were plenty of evil people who did good things, and plenty of good people who got blood on their hands achieving and attaining higher goals.\"), Sentence(\"Bad situations that had good long term effects,...|||You would have to ask the OP.\"), Sentence(\"He is asking ambiguous questions.\"), Sentence(\"I would go with whatever is more efficient/effective vs what is perceived as good every time in the good vs evil dichotomy.\"), Sentence(\"It in my...|||Good vs Bad =/= Good vs Evil One is an objective positive vs negative dichotomy, the other is a subjective interpretation of characteristics.\"), Sentence(\"NameUser  So to be evil may be a better solution and...|||I think they are for sure idiots, but I also think these people went out of their way to fuck their lives up.\"), Sentence(\"Did they expose themselves on the internet?\"), Sentence(\"Yes.\"), Sentence(\"Does this warrant or validate a reason...|||I really REEEEEEAAALLLY hate rigidly PC thumb sucking nanny bitches.\"), Sentence(\"They remind me of five year olds who are trying too hard to gain their parents approval by taddling.\"), Sentence(\"These are the same people,...|||I think people need to get some skin.\"), Sentence(\"Even if these people are wrong or racist.\"), Sentence(\"That's just a waste of time, energy, and resources.\"), Sentence(\"These people end up being the focus for being petty and overboard...|||http://www.penciltribe.com/cms/wp-content/uploads/2013/04/Brian_snowflake-300x225.jpg|||http://www.penciltribe.com/cms/wp-content/uploads/2013/04/Brian_snowflake-300x225.jpg|||I'm not trying to be condescending when I tell you- all those things you have mentioned people saying and have written off as all I have been met with are legit arguments.\"), Sentence(\"They don't need to be...|||The brevity of my posts is because you don't take much to refute.\"), Sentence(\"Just because you aren't acknowledging what people are saying doesn't mean they are saying nothing.'\")]\n",
      "[Sentence(\"'18/37 @.\"), Sentence(\"@|||Science  is not perfect.\"), Sentence(\"No scientist claims that it is, or that scientific  information will not be revised as we discover new things.\"), Sentence(\"Rational  thinking has been very useful to our society....|||INFP- Edgar Allen Poe was an INFP and he's in your siggy.|||People see the obvious Fi and are quick to put her as INFP.\"), Sentence(\"I agree that she has no Ne.\"), Sentence(\"I see her as an ISFP.\"), Sentence(\"Compare her to Haku (definite INFP).\"), Sentence(\"She is flat through most of Naruto.. but I don't...|||Lets get this party started  66314|||I did not say it disproved God.\"), Sentence(\"I merely said that I found such methods disturbing.\"), Sentence(\"Although, it does bring up certain questions.\"), Sentence(\"God is in control of the universe, and the governments of the world,...|||Surprisingly, I could not find a thread about this on perc even with Google.\"), Sentence(\"So, here you go.\"), Sentence(\"Watch Jesus Camp online - Watch Movies Online, Full Movies, Download  I was disturbed watching this...|||A metaphysical gun (Hell) held to someone's head can be just as effective as an actual gun.\"), Sentence(\"Do you not find these methods disturbing?\"), Sentence(\"Watch Jesus Camp online - Watch Movies Online, Full Movies,...|||Unstable is not the right word.\"), Sentence(\"We are usually pretty emotionally flat-lined.\"), Sentence(\"But, when we do have to deal with our own emotions we can be very bad at it.\"), Sentence(\"In high school my feelings of attraction...|||Well, I went to someone's wedding and dipped everything in the chocolate fountain and ate it.\"), Sentence(\"I dipped the fruit, the fish, and even the Hershey's kisses.\"), Sentence(\"And I drank two little jars of honey they...|||That post you  quoted was from two and a half years ago.\"), Sentence(\"Since then, I've come to a better explanation.\"), Sentence(\"INTPs may not be as externally certain as INTJs, but they are more certain internally.\"), Sentence(\"They...|||This is how I deal with the INFP I'm in a relationship with.\"), Sentence(\"I am often tempted to avoid hurting them even if it means fudging the truth, telling them only what they want to hear.\"), Sentence(\"If I do that, it...|||Never heard of it till now.\"), Sentence(\"I watch a loooot of anime, but I get it from animedreaming.tv mostly; I am not a member of any anime board.|||The legs are nice, but her expression is all wrong.\"), Sentence(\"That is not her private sad face; I don't know what it is.\"), Sentence(\"See, I have her evil grin <B|||Kokiri Connect.\"), Sentence(\"Becuase I couldn't rememeber how to spell Kokoro Connect so I let Google do it.|||Inaba from Kokoro Connect.\"), Sentence(\"Because I relate to her and I enjoy looking at her (I have to look at my avatar alot).|||I'd like to see someone react when they are told they have   hippopotomonstrosesquipedaliophobia.|||She doesn't trust you or respect you.\"), Sentence(\"A break would be good to test if she will change.\"), Sentence(\"If she doesn't, you have to think about what will make you happy in the long term.\"), Sentence(\"Next time, establish ground...|||I don't think any INTJ is not going to do this if they have a choice.\"), Sentence(\"Though, until I got the internet in my late teens I didn't explore many subjects I was interested in in depth.\"), Sentence(\"Of course, it...|||No, I don't smoke.\"), Sentence(\"I have an addictive personality, and I don't think I would be able to stop if I started.|||Destroying his reputation by revealing what he has done could cause him to lose a lot of power... but if people knew things he had done, a certain person would kill him and end up in jail.\"), Sentence(\"There...|||People like people like themselves; this is the number 1 indicator of attraction.\"), Sentence(\"Seeing as most people are sensors it is not surprising that they do not care for my personality.\"), Sentence(\"Woman have...|||My best friend is an INTJ.\"), Sentence(\"We have so much in common even for two INTJs; she understands me better than anyone.\"), Sentence(\"It took a loooong time for us to become close.\"), Sentence(\"We put up a lot of barriers.\"), Sentence(\"I get...|||I can tell you about a sociopath I know in real life.\"), Sentence(\"Not an INTJ, an ENTP or INTP.\"), Sentence(\"-Tells all his problems to people shortly after meeting them to attempt to gain their sympathy so they can be...|||Light (at least in the beggning) and Lelouch did ultimately have good goals, even if their methods were evil.\"), Sentence(\"Lelouch did seem to feel remorse at times; a sociopath would never consider taking...|||Nobody panics when things go  according to plan.\"), Sentence(\"Even if the plan is horrifying.\"), Sentence(\"If tomorrow I tell  the press that like a gang banger, will get shot, or a truckload of  soldiers will be blown up,...|||1.\"), Sentence(\"Code Geass  2.\"), Sentence(\"Steins; Gate (It was hardest to pick between this and Geass, but I  think Geass just barely beats it.\"), Sentence(\"I will say it is very slow in the  beginning, but everything that happens in...|||Looking back at this post from 2.5 years ago... Emil, Asahina, and Hinata are actually ISFPs.\"), Sentence(\"Maybe Kimmimaro and Alphonse as well.\"), Sentence(\"I really don't know Li Xingke's type... its been awhile since I...|||Focus on learning the system, and the details should fall into place as you go along.\"), Sentence(\"For example, learning C++, I read about how it worked, then wrote some programs and only bothered figuring out...|||glad you recognize my username.\"), Sentence(\"Yes, until you said INFJ (that type uses Fe/Ti).\"), Sentence(\"The four types that use (Fi&Te)/(Te&Fi) are in my previous post.|||INFP- Going out with one now.\"), Sentence(\"We don't understand each other in some ways (though understanding is a lot better than most type matches), but we challenge each other and help each other grow.\"), Sentence(\"We have...|||Welcome.\"), Sentence(\"Now bring me some Pizza.\"), Sentence(\"Actually, that could happen to me after I'm done with my English degree XD|||You need to think about the reasons for what you want and about how realistic each of your goals are.\"), Sentence(\"Maybe one is more of a fantasy and one is actually worthwhile?\"), Sentence(\"That's what I would do anyway,...|||What my previous post said was: you seem like a dominant Fi.\"), Sentence(\"Do you do all this Ne thing or this FiNe thing.\"), Sentence(\"Put into terms that the OP understands.\"), Sentence(\"The 8 letters are intended to be shorthand for...|||You seem like an obvious I, F, and P. INFP is the strongest possibility.\"), Sentence(\"Possibly ISFP, though.\"), Sentence(\"How do you brainstorm?\"), Sentence(\"Do you overthink things?|||Combining your anxiety and avoidance scores, you fall      into the secure quadrant.\"), Sentence(\"Previous research on attachment styles indicates that     secure people tend to have relatively enduring and...|||I don't think you can simply reach into your mind anytime to tell if you love someone.\"), Sentence(\"Perhaps you have fantasized for a long time and expect a real relationship to be like that in some ways.\"), Sentence(\"But...|||I don't think its impossible to doublethink, only impossible to remain in that state (which could explain why oceania fell after the end).\"), Sentence(\"The hard atheists I do not disagree with.\"), Sentence(\"Anyway,...|||Cows are a religious subject (Hindu) XD   If the denial of a religion is a religion, then most or all of us here are ascientologists, for example.\"), Sentence(\"Most everyone would have, what?\"), Sentence(\"at least thousands...|||By that definition anything could be defined as a religion by attaching the suffix -ism... and then the word religion loses its meaning.\"), Sentence(\"I would say that religion has both a precise and general...|||There are no practices required to be an atheist.\"), Sentence(\"All that is required is a disbelief in deities.\"), Sentence(\"Other than that, atheists can have widely different beliefs.\"), Sentence(\"It is too general a term to be called a...|||My guess is ENTP, though it is hard to say just from this.\"), Sentence(\"Have you studied up on cognitive functions?\"), Sentence(\"If not, learning how each works and identifying which ones you use would be very helpful.|||I believe it has gone  through too many human hands to be thought of wholly as the word of God  (or to be followed unquestionably).\"), Sentence(\"Yes, most useful when thought of as  a text by man about God.\"), Sentence(\"...|||Apparently, you need to pose as a gay guy to pick up women.\"), Sentence(\"But, seriously.\"), Sentence(\"Its 2012.\"), Sentence(\"You have a world of media at your fingertips.\"), Sentence(\"In a poll that appears to be from eHarmony (though it is...|||We are playing a game called Mafia.\"), Sentence(\"We have to vote on who to kill for this round, who we think is part of the Mafia.\"), Sentence(\"Rob (names made up) says, kill Joe.\"), Sentence(\"I suggest killing Rob.\"), Sentence(\"Rob says, Don't...|||what you need to know as an INTJ fiction writer: http://phantomshine.blogspot.com/2012/05/writer-analysis-through-mbti.html   I grow tedious of gratuitous visual details... though, images are...|||Bolded are ones I actually live with.\"), Sentence(\"Mother- ISFJ Father- ISTJ Sister- ISTP Half-Sister- ESFJ?\"), Sentence(\"Grand-mother (mother's side)- ENFP Step-brother-ESFP Step-father- ESFP?|||Very interesting.\"), Sentence(\"Explains why these two types often see each other as close-minded or arrogant.|||There are as many INTJs as there needs to be.\"), Sentence(\"If everyone is a leader, who is going to follow?\"), Sentence(\"And who is going to take the jobs that no intuitive would want?\"), Sentence(\"There is a part in Brave New World where...|||Mm, probably INTP now that I have become more familiar with that type.'\")]\n",
      "[Sentence(\"'No, I can't draw on my own nails (haha).\"), Sentence(\"Those were done by professionals on my nails.\"), Sentence(\"And yes, those are all gel.\"), Sentence(\"You mean those you posted were done by yourself on your own nails?\"), Sentence(\"Awesome!|||Probably the Electronic Screen Syndrome.\"), Sentence(\"With the advent of technology and social media, we all suffer from overstimulation on a daily basis.\"), Sentence(\"I'm guilty as well.\"), Sentence(\"In the past, I can be happy just...|||I love nail arts too!\"), Sentence(\"These are some of mine:  718282 718290 718298 718306 718314|||This is the first time I'm hearing this - about menstruation and church.\"), Sentence(\"Thanks for sharing but yeah, it's crazy.\"), Sentence(\"I thought only Taoists have such a belief.|||Dear very bad person,  Not trying to get in between your arguments but I'm copying down that sentence for future use.\"), Sentence(\":tongue:|||*Speaking from a bomb shelter*  So which Christian values do you still hold?\"), Sentence(\"I agree that people can still be good in the absence of religion and people also do bad in the name of religion but the...|||I never really thought about my childhood experiences until I was much older when my brothers and I talked about the past and we all agreed that we had suffered physical and verbal abuse.\"), Sentence(\"It wasn't...|||My ISFJ friend almost always instantly shuts down and becomes upset whenever someone disagrees with her POV or the way she does things.\"), Sentence(\"She can't seem to understand why a certain behaviour, though...|||These two questions seem unrelated.\"), Sentence(\"If people know my real thoughts, they may or may not like me better, it depends on whether they like my thoughts to begin with.\"), Sentence(\"I have bad thoughts but some...|||BSI don't BS.|||I think INFJs sometimes need to be kicked out of our comfort zones, for the sake of our emotional wellbeing.\"), Sentence(\"-- I can relate to this and it actually helps when friends pull me out of my rut.\"), Sentence(\"I...|||Haha... sorry if I offended anyone.\"), Sentence(\"I don't mean for this to be a dirty jokes thread.\"), Sentence(\"I've amended the original.\"), Sentence(\"That was a funny one you shared, btw.\"), Sentence(\"I recalled a similar situation which...|||LOL, can I pay that in instalments?|||Yes, and this is a double edged sword.\"), Sentence(\"I think mental health awareness and education are important, and what's more important is people need to know where to get help.\"), Sentence(\"On the flip side, I'm also...|||Haha, hopefully?\"), Sentence(\":proud:|||I'm not calling out recent posts specifically, just the general overall.\"), Sentence(\"Some posts may have been made several years ago but their remarks still stand.|||I'm creating this as a stress-reliever as I think all of us can use a good laugh once in awhile... :tongue:    Perhaps I'll start off with this funny conversation between two friends who were...|||I have a thinking... that many INFJs think they suffer from trauma but a lot times it's actually just us torturing ourselves in our minds because we're so good at that.\"), Sentence(\"I talk it out with...|||So many stereotypical statements here.\"), Sentence(\"The way you guys describe the girly girls are like a princess.\"), Sentence(\"Pls label them as princess instead.|||Mental health is such a in-thing nowadays a lot of people are slapping labels on themselves to look cool.\"), Sentence(\"I'm not saying all of you are doing that...\"), Sentence(\"I'm just saying don't do that.|||Researchers are always coming up with new studies and BBC is hardly a reliable source.\"), Sentence(\"Even if you identify with a few symptoms on the checklist, it doesn't necessarily make you a psychopath.\"), Sentence(\"It's...|||I think this sucks and you have my sympathy.\"), Sentence(\"Personally, I hate it when a guy dumps me for another gal and then tells me he wishes me happiness when he's the exact source of my unhappiness.\"), Sentence(\"Don't buy...|||EveJ, I agree with the INTJ who says other people's expectations are other people's problems.\"), Sentence(\"I'm quite sick of meeting people's expectations simply because they feel entitled.\"), Sentence(\"The truth is, when the...|||Ashton Vern This may help you further - https://thoughtcatalog.com/heidi-priebe/2015/07/how-to-recognize-each-myers-briggs-personality-type-in-real-life/|||Only once.\"), Sentence(\"I confessed to him.\"), Sentence(\"He loves me back.\"), Sentence(\"We were together for 7yrs, then we broke up.\"), Sentence(\":crying:  Unbreak my heart, pls.|||fabi, OMG, I finally found someone who also love these morbid subjects!\"), Sentence(\":blushed:  I don't know if this is caused by Ni-Ti and if other INFJs also generally love such topics because my INFJ friend...|||Green, orange, white, yellow or red?|||I must say that this is by far the first religious thread I've read that didn't erupt into a war (lol) :joyous: so I feel safe posting here.\"), Sentence(\"I grew up as an atheist and later became a believer of God...|||Above ground or underground?|||What I mean by realistic is when we use Ti to analyse a situation.\"), Sentence(\"When I get into high Ti mode, I can really zoom in on the facts and question everything that's happening - happening in real life,...|||xtctr Have you done a MBTI test or you just think you're an INFJ because you feel lonely?\"), Sentence(\"Because you said you didn't feel this way up until this year...\"), Sentence(\"So why is it that you suddenly feel...|||For I know the plans I have for you, declares the Lord,  plans to prosper you and not to harm you,  plans to give you hope and a future.\"), Sentence(\"- Jeremiah 29:11|||I don't think trauma makes an INFJ or all INFJs must have experienced trauma.\"), Sentence(\"This is like saying other types don't experience traumas and it sounds rather snobbish.\"), Sentence(\"When we experience trauma, we...|||You're right that INFJs can be very idealistic, but those with a strong Ti can also be very realistic as well, especially if we go into Ti overdrive.\"), Sentence(\"After reading this, I still don't think...|||Hi Ashton Vern I doubt your friends are INFJs.\"), Sentence(\"See my point-by-point below...  -------------------------------------- Characteristics of Friend A: - very friendly and caring.\"), Sentence(\"She cares for her...|||Transition.\"), Sentence(\"Anxiety.\"), Sentence(\"Prayers.|||https://www.youtube.com/watch?v=tuunqfdz388|||IDontKnowMe  When did you have your first relationship (<20, 20-25, 26-30, >30)?\"), Sentence(\"<20  What do you look for in a partner?I like guys with boyish good looks, :wink: with a good heart and good...|||I want people to understand me but I won't bother telling them my type because most of the people around me don't seem too bothered with MBTI.\"), Sentence(\":dry:|||Comfortably 2 hrs, maximum 3 hrs and then the full army of Ni barges in and I'm not paying attention anymore.\"), Sentence(\"Depends on how interesting the conversation is... shut down can happen earlier.|||Gotterdammerung  My brother had night terrors when he was young.\"), Sentence(\"He would wake up EVERY NIGHT at the EXACT SAME TIME and cried about someone trying to catch him.\"), Sentence(\"It was traumatising just watching...|||There was a period I had dreams of ghosts and when I woke up in paralysis mode I saw them in my room/outside my window.\"), Sentence(\"Another time I dream of a ghost in my room and then my spirit self saw myself...|||Yes, I also read that everyone dreams.\"), Sentence(\"At one time I did quite a bit of research on dreams because I was dreaming so much and some were rather supernatural.\"), Sentence(\"Lucid dreaming is interesting but...|||More or less... but what I don't fit is some people think INFJs will never go to a club or anywhere noisy.\"), Sentence(\"This is untrue of me.\"), Sentence(\"I love music festivals, concerts, dancing to my favourite songs in a...|||How do you lucid dream on purpose?|||I like all the badass quotes:  712170  712178  712186  712194|||It is said that the INFJ minds don't switch off.\"), Sentence(\"I believe mine doesn't switch off even when I sleep which is why I'm such a prolific dreamer.\"), Sentence(\"My dreams are also often vivid, prophetic or sometimes...|||Emotional connection to me is to be able to relate our feelings (sadness, anger, joy, love) with one another.\"), Sentence(\"Sometimes I can feel an instant emotional connection with a friend over a particular...|||Not very good at doing romantic things... perhaps the most romantic thing I've done is folding a bottle of wishing stars for my boyfriend?|||Are you collecting MBTI types?\"), Sentence(\"LOL  Perhaps you can learn to spot them:  1.\"), Sentence(\"The one sitting in a crowded room quietly but observing everyone like a hawk (or creep).\"), Sentence(\":ninja: 2.\"), Sentence(\"The one who looks...'\")]\n",
      "[Sentence(\"'I tend to build up a collection of things on my desktop that i use frequently and then move them into a folder called  'Everything' from there it get sorted into type and sub type|||i ike to collect odd objects, even at work...a lot of people would call it junk but i like to collect it.\"), Sentence(\"Old unused software?\"), Sentence(\"ill take that off your hands :) i have a bunch of old adobe...|||i think its quite normal, i tend to only see my friends in real life every couple of months, as said earlier some people just dont get it but the good ones do :)  Edit: i mostly mean tolerate it...|||where do we go when we sleep?\"), Sentence(\"is dreaming another form of being awake?\"), Sentence(\"how many more layers of this are there if any?\"), Sentence(\"thoughts about sleep keep me up at night  Edit: sometimes im too scared...|||thanks|||i wish i was free to follow my interests as i desired  i feel as though wishes are meant for impossible things|||by seeing do you mean visual interpreting or seeing as in mentally understanding the concept?|||hello|||i feel as though i am incapable of creating anything   and i wish i could|||i cant stand the interviewer christ that laugh...  is he intj?\"), Sentence(\"hmmm  it would be interesting to see an intj on this show, i doubt they would be that interesting to the general public though ...|||know yourself and be yourself|||Do you think Fi or Fe sounds more like me?\"), Sentence(\"which one do you think sounds like you?\"), Sentence(\"Why do you require input from others to know what you are?|||Question: do INTJs lean more towards Alternative Rock then other types of music?\"), Sentence(\"And if so, why?\"), Sentence(\"My Answer: well, if you went through all the pages and then sorted all the songs by genre/style...|||sometimes i look at people and i see them , well on the outside at least, doing all these things and saying all these words and i wonder what it would be like to act that way... am i missing out on...|||a lounge huh?\"), Sentence(\"what does one do in a lounge?\"), Sentence(\"or is it best not to define it and just enjoy it as is?|||Do it|||went on holiday for just over a month, thought things would change.\"), Sentence(\"How naive of me..  feels nice to browse back on this forum here though, its been a while since i surrounded myself with somewhat...|||yes i would say i am, more than physical appearance to an certain degree.\"), Sentence(\"what are they?\"), Sentence(\"i am unsure they just generally cant be a terrible person by my standards|||i like to lurk, in my case at least its mostly because i tend to believe i have nothing interesting to contribute to the conversation so why add anything?\"), Sentence(\"logging out to purposely lurk seems like...|||i think id wait for him to swing first before taking further action but i would not  encourage them to take a swing  a part of me wants to fight him though...|||would you say there is complexity in simplicity?|||I normally vote for whoever amuses me the most..  perhaps one day i'll care more  Edit: other than what amuses me at the time, ill vote for whatever would apparently benefit me the most....|||long distance is hard|||INTJ's and what effects their sanity levels  Mental illness|||So i think about which thoughts i wish to express in written format, then i proceed to perform the physical movements necessary to express the required thoughts in whichever medium is required or...|||651762 i got this, seems right to me.\"), Sentence(\"I always score intj, extra heavy on the introversion :3|||I like this  https://www.youtube.com/watch?v=e4dT8FJ2GE0  I like the sound, the content/lyrics are not too important, the sound is what i value most.\"), Sentence(\"Is it my favourite?\"), Sentence(\"probably not, i heard...|||to others maybe, although internally i am acutely aware of any mistakes i have made|||assuming they would listen to me, i would each give them a solo task that leads to the successful completion of the project  how would i make them listen to me?\"), Sentence(\"explain that the success of the...|||i am a fan of the idea that a celestial being died and its essence became everything we know, what kind of sacrifice would have to be made to create such wondrous things?\"), Sentence(\"(stars, planets, cosmic...|||Nah|||1) Since when do you need a manager present to make returns??\"), Sentence(\"or was it because I work there?\"), Sentence(\"- check the company policy on this 2) Why did they want to save my receipt?\"), Sentence(\"-not sure, perhaps to...|||i remember my first encounter with this type of music was BOA - Hurricane Venus, saw it played on a starcraft 2 stream round 201011 or something and was kinda hooked.\"), Sentence(\"Don't follow/watch it much...|||what happens when this riddle gets solved?\"), Sentence(\"what use is this information?\"), Sentence(\"haha i am clearly not a fan of riddles  Edit thoughts: Girlfriend asked me a few riddles and it was infuriating for...|||i kept pressing them to talk about something they didnt want to, i regret it deeply|||It is not hands that summon us.\"), Sentence(\"It is desire.\"), Sentence(\"I want nothing to do with that puzzle box.\"), Sentence(\"Nope.\"), Sentence(\"Nope.\"), Sentence(\"Nope|||i used to think life was dull and everything was boring, then i realised that i havent actually done everything so it felt incorrect in thinking that way|||ahh yes the pain of living, its beautiful isnt it?|||i got   Your score for openness was 70%.\"), Sentence(\"This is in the moderate range.\"), Sentence(\"Your score for conscientiousness was low, at 35%.\"), Sentence(\"Your score for Extraversion was low, at 15%.\"), Sentence(\"Your score for...|||What do you mean by humanities?\"), Sentence(\"i like to think about the direction of the human race as a species and i like to appreciate where weve come from so i guess i love humanities?|||1.\"), Sentence(\"Attempt to think less about things 2.\"), Sentence(\"Be more decisive and confident in my decisions/thoughts (i cant help but play devils advocate with myself, i guess this ties into number 1) 3. change my...|||Ahh yes that sinking feeling when something goes incredibly wrong or not to plan.\"), Sentence(\"How do i get over it?\"), Sentence(\"embrace the madness, how are you going to deal with your scenario now with all these new...|||I like to imagine it kinda like this 629346  except the ring is a billion times higher and nearly impossible to scale and then in the middle is a beautiful garden and house where i like to chill....|||if you look at the first sentence of most of them you can gather the feeling they are trying to portray, followed by a rather nice scenario.\"), Sentence(\"So yes i do feel those feels, but not for those...|||I think its the introversion crossed with the feels that does it for me.|||first encountered mbti?\"), Sentence(\"hmm was a personality test i took in highschool, didnt care or even pay attention to it until later.\"), Sentence(\"stumbled upon it somehow and was interested  Im not too into it as...|||Treat Yo Self|||Question: Can INTJs be try-hards?\"), Sentence(\"Answer: sure|||No im not, our values of friendship are clearly different.\"), Sentence(\"An emotional investment of any kind is a big deal to me, a HUGE deal, to have it not appreciated and/or reciprocated is soul destroying.\"), Sentence(\"...|||petty?\"), Sentence(\"perhaps, but why bother with someone who isnt going to give me what i want when i can just move on?\"), Sentence(\"what a waste of my time and emotional energy.\"), Sentence(\"Hopefully for you this friend of yours is...'\")]\n",
      "[Sentence(\"I'm not sure, that's a good question.\"), Sentence(\"The distinction between the two is so dependant on perception.\"), Sentence(\"To quote Robb Flynn, ''The hate you feel is nothing more, than love you feel to win this war.\"), Sentence(\"''|||Good question!\"), Sentence(\"It's tough to say for sure but I loved Winona Ryder as Lydia in Beetlejuice...  http://i63.photobucket.com/albums/h158/trinsghost/Misc-Images/2921aa070866f20450f8e1160b1e5d41.jpg|||https://www.youtube.com/watch?v=r5If816MhoU|||https://www.youtube.com/watch?v=Q-sQklvpDhA|||I've been lonely for much of my time.\"), Sentence(\"For a while now I've been working on changing ''how to think'', and one way is trying to find the positive in everything, no matter how bleak it might seem.\"), Sentence(\"I...|||I hope I can look back at this current stretch of time and think, ''Thank God I'm not there anymore and things are so much better''.\"), Sentence(\"What an ass-kickin' I'm taking.|||Help or a voice of reason, other than my own distorted, in my life.\"), Sentence(\"I'm completely frusterated and feel like I'm on the brink.\"), Sentence(\"I'm carrying the weight of everything negative I've ever had in my life...|||Think I posted this before but I'm still feelin' it....   https://www.youtube.com/watch?v=Cu8qsC1WLiE|||Fleeting thoughts of acknowledging and getting lost in the depth love that we share for one another.\"), Sentence(\"It could be the most mundane thing but every now and the simplest act will make me appreciate the...|||https://www.youtube.com/watch?v=pULe7-6yRo4|||I've been told that I'm OCD and I'm aware of it.\"), Sentence(\"For me it's more than just obsessive cleaning and things of that nature.\"), Sentence(\"I've come to understand how it affects things such as obsessing on a thought...|||https://www.youtube.com/watch?v=XkbQDChgmX8|||I'm working on a song I've been trying to learn for just about a year.\"), Sentence(\"Was hoping to finish it before the New Year but still have a ways to go.|||Sons of Anarchy is the first TV series I've followed since The X-Files WAY back in the day.|||https://www.youtube.com/watch?v=2R2NrV4ve1o|||Fleeting|||I'm not a big book person but every now and then I go through stages and force myself to read more than I normally do.\"), Sentence(\"One book that always stands out in terms of interest while reading was ''Venus...|||https://www.youtube.com/watch?v=9utPTpXpIgE|||Frustration got the best of me today, and has been a lot lately.\"), Sentence(\"Having a couple Heinekens right now and feel a bit better.\"), Sentence(\":) This is a difficult time, and is going to be for a bit, gotta maintain.|||Find balance, get more in harmony with life and position myself to capitalize on any opportunity that presents itself.\"), Sentence(\"Within that lies the path to a more fulfilled life, at least I'm hoping.\"), Sentence(\";)|||https://www.youtube.com/watch?v=RoL0nRuHj0I|||I'm not a touchy-feely person and don't care for folks I don't know feeling up on me.\"), Sentence(\"My response depends greatly on the person doing it.\"), Sentence(\"Some people are just naturally affectionate and it's their...|||https://www.youtube.com/watch?v=oYZh9yQu1fo|||https://www.youtube.com/watch?v=d5abdXpvBR0  ...Very frusterated, wrestling with thought, and not winning.|||Escape From Alcatraz|||https://www.youtube.com/watch?v=u8lOTMMRJZg|||https://www.youtube.com/watch?v=-ls5mug1_KU|||I'm grateful to still have a little time to make good of all the things I've learned the hard way through countless mistakes and wrong turns.|||https://www.youtube.com/watch?v=ff_6BF37fI0|||A great song to start the day...   https://www.youtube.com/watch?v=YnHaYVYFTU8|||Joints hurt a little, other than that I feel the same old usual indifference.\"), Sentence(\":P|||An early 90's style Ford Mustang GT with the more square body.\"), Sentence(\"In all reality, one can be found for a few thousand dollars which makes this dream car very attainable.\"), Sentence(\":)|||http://www.youtube.com/watch?v=Cu8qsC1WLiE|||It was kind of intended to have a dark, terrible to feel about it.\"), Sentence(\"Depression has many depths, and those levels vary from person to person.\"), Sentence(\"I've dealt with serious depression my whole life and it...|||http://www.youtube.com/watch?v=QnRkiAK_gZc|||http://www.youtube.com/watch?v=66Vc-2CS4ew|||Comfort food - Pizza and chicken wings, cheesecake or pumpkin pie  Comfort drink - Redbull, Guinness or Red Wine|||Still grinding out this song on guitar, it's coming along but slowly and most certainly not easily.|||Some vague advice I can give is this, it can always be worse and in most cases it probably will be someday.\"), Sentence(\"So it works to look at any current situation like this, it helps to appreciate what you...|||Content, not happy but more content than I've been in a while, a LONG f'n while.\"), Sentence(\"I'll take it.|||For breakfast I had a piece of grilled chicken and a Guinness.|||-Seven -The Decent -Rocky -Heat -Silence of the Lambs|||http://www.youtube.com/watch?v=gvYm6kVY2IE|||Robb Flynn of Machine Head, Michael Amott of Arch Enemy, Jerry Cantrell of AIC.\"), Sentence(\"Edit: Forgot to include Zakk Wylde, a musical genius.|||Pucca...That shirt could be a lot of fun indeed.\"), Sentence(\":)|||....Watching a video of Megadeth live on the Big Four Tour.|||http://www.youtube.com/watch?v=2XhGQisD040|||JungleDisco...Takin' it back with Silk.\"), Sentence(\"Great Stuff.\"), Sentence(\"http://www.youtube.com/watch?v=9uhLDWCqSQQ|||Rockin' some Down right now.....\"), Sentence(\"http://www.youtube.com/watch?v=aKfmYGlhWWk|||....I currently desire for July 20th to roll around so I can finally see Machine Head live at this years Mayhem Festival.\"), Sentence(\"F**k yeah.\"), Sentence(\"http://www.youtube.com/watch?v=lK588zl0l2M\")]\n",
      "[Sentence(\"'https://www.youtube.com/watch?v=w8-egj0y8Qs|||I'm in this position where I have to actually let go of the person, due to a various reasons.\"), Sentence(\"Unfortunately I'm having trouble mustering enough strength to actually pull through it.\"), Sentence(\"Sometimes,...|||WHAT A YEAR, MAN.\"), Sentence(\"WHAT A YEAR.\"), Sentence(\"I am just utterly bewildered with my 20s at this point.|||my laundry.\"), Sentence(\"as long as i've got clothes left to wear i'm fine.\"), Sentence(\"and then the time comes that i DO run out, and i'm left to contend with The Mountain that is my laundry pile.\"), Sentence(\"Sent from my Apollo...|||http://www.youtube.com/watch?v=Xyix3xdRd3Y|||going back to the office in a few hours.\"), Sentence(\"back to being dumbstruck and confused by your presence, back to being on the edge 90% of the time, back to feeling duplicitous, and hopelessly despicable,...|||i followed Scott Disick on instagram and so far i'm not regretting it lol.\"), Sentence(\"douchebags amuse me to no end.\"), Sentence(\"Sent from my Apollo using Tapatalk|||you are SO quiet!\"), Sentence(\"you have beautiful hair.\"), Sentence(\"you're too damn logical, i like it.\"), Sentence(\"you make me feel like a lesbian at times|||i miss the beach so badly, that vacation was definitely not enough.\"), Sentence(\"i don't want to work yet i need a longer breather i wanna go baaaaaaaaccckkkk|||i've waited so agonizingly long for this moment and now that the chance is here my indecision and procrastination has decided to present their Amazing Super Powers in the worst way possible.\"), Sentence(\"i...|||do i text her or not do i text her or not do i text her or not do i text her or not do i text her or not   do or do not.\"), Sentence(\"there is no think|||Natalie Dormer literally looks like a cat sometimes.|||i find scars fascinating to be honest.\"), Sentence(\"our bodies' own version of short stories.\"), Sentence(\"i have a nice collection myself, mostly from bike accidents when i was a kid.|||that would make quite an awesome scar though.\"), Sentence(\"i hope it doesnt hurt too much.|||galumphing on the net, drowning myself in music, relationship issues, overthinking in general + i feel fine/nothing|||http://www.youtube.com/watch?v=Y4cxaVEqZsE  apart from the hardcore yeehaw country songs, i absolutely love True Detective's soundtracks.|||i feel like i want to just eff it all up and break up with my SO just because i'm too distracted with this other person right now.\"), Sentence(\"i cannot stomach my own burgeoning dishonesty.|||lol.\"), Sentence(\"my SO always seems unnerved by that look.\"), Sentence(\"he's commented before that i look like i'm planning a murder in my head or envisioning the edges of the matrix, when i was really only calculating the...|||most social media words like trending, viral and selfie  whenever i hear those words i suddenly transform into this barmy-old luddite codger and bemoan how excruciatingly vacuous and fleeting...|||i cannot remember the last time i was this attracted to anyone and it absolutely terrifies me; how i lose concentration, how everything is heightened by the sense of your presence, how every possible...|||http://www.youtube.com/watch?v=j9rIHPvm5c0|||or sometimes, just dispense with the apologetic message altogether.\"), Sentence(\"i find that goodbye to be more effective, though i have no idea how many lives i've managed to ruin in that process :mellow:   ...|||http://www.youtube.com/watch?v=pM_Q-G_CZ74|||i can be so damn full of sh!t sometimes.|||this.\"), Sentence(\"oh my god.\"), Sentence(\"it just can't be helped.\"), Sentence(\"whenever i'm sitting in a relaxed position tapping a beat just happens automatically, and my patterns tend to reflect whatever mood the immediate surrounding...|||sometimes patience really is a curse.|||i've learned to control my disdain for such types, since my job involves me explaining things all day round to people with absolute-zero comprehension, requiring inhuman levels of patience.\"), Sentence(\"what...|||sometimes it just makes so much sense, it scares me.|||ohhh i'm with Emma on this one.\"), Sentence(\"she pushed the song so hard i actually ended up youtubing the entire thing, only to realize i like her lipsync version better :kitteh:|||life would be so damn easier if we all harbored ESTPs in our heads and would let them out whenever there's a social situation.\"), Sentence(\"i cannot count the number of times i froze out of a conversation i...|||i wish the whole MBTI system had some sort of vitamin-juice merchandise going on, like an inversed polyjuice potion wherein it'll be your attitude to change, not your facial countenance.\"), Sentence(\"god...|||ikr!\"), Sentence(\"i hope they play with it more, i wouldn't even be against it if they turned it into a full fledged movie.\"), Sentence(\"although if ever they do, i hope they don't blow it all out of proportion.|||stepping on dry leaves and hearing the crunch cup of coffee while browsing the internet the latest episode of your favourite tv show finally uploaded in torrent the fresh feeling after taking a...|||oh god this show was so, so good.\"), Sentence(\"one of the best sci-fi shows to date.\"), Sentence(\"i love how the writers seem to backstab technology by emphasizing the repercussions of having said advancement.\"), Sentence(\"and i'm still...|||http://www.youtube.com/watch?v=6XXfqPRG4TQ|||Orphan Black, people.\"), Sentence(\"Orphan Black.\"), Sentence(\"season 2 just started last night, and there are only 10 episodes from season1 to catch up on.\"), Sentence(\"i binged it last summer and it ruined my life.\"), Sentence(\"the lead actress...|||considering going back to tumblr just to be up to date with all the Orphan Black posts.\"), Sentence(\"how can i be so obsessed with a damn tv show??\"), Sentence(\"?|||default feeling: i feel fine/nothing.\"), Sentence(\"althought if you can equate contentment to being happy, then yes, i am happy sometimes.\"), Sentence(\"but it never really lasts.\"), Sentence(\"lol INTPs are such a cheerful bunch|||you need to be very patient with INTPs, so just stay put.\"), Sentence(\"most likely she's still rationalizing her feelings for you, which is normal INTP thought-(feeling)-process, hence the confusing interactions....|||i prefer anything mystery or with a sci-fi undertone, dark films with plenty of things to mull about.\"), Sentence(\"i will watch anything by Nolan, Haneke, Almodovar or Fincher.\"), Sentence(\"as a rule i avoid action films and...|||http://www.youtube.com/watch?v=mqGhSR0z1fw  right now she's got to be one of the most judged artists in the pop scene, what with her gloomy look and fashion association and drug problems.\"), Sentence(\"i just...|||my 6 year old niece always says the most absurd things like she's some hipster on an acid trip:  i want flying bread it tastes like atmosphere *random japanese-sounding words to assimilate an...|||^ the series does require patience, but i suggest you try stick to it as much as you can because the pay-off is immense.\"), Sentence(\"or, watch the show to help you understand the plot better.\"), Sentence(\"the books can be...|||at this point if walking away from a person is the basis of excellent social interaction, then i'd be a damn socialite.|||from my point of view, for us INTPs love is like a faucet, it won't shut  off until you actually turn off the tap.\"), Sentence(\"so no matter the circumstance,  if he loves you still, then taking your time with...|||i had the same exact moment like this last year, when the faking it part just became a bit too much to stomach.\"), Sentence(\"right now i'm in a well-paying job, have my own place, live independently and...|||when someone takes way too long to explain their damn point.|||what house are you?\"), Sentence(\"Targaryen  who's your favorite character?\"), Sentence(\"the Lannister men (Tywin, Tyrion and Jaime), Daenerys Stormborn, Arya Stark  best storyline?\"), Sentence(\"Dany of course.\"), Sentence(\"who can beat rearing...|||i suck at math but i'm great at English.\"), Sentence(\"words make more sense to me than numbers, unfortunately.\"), Sentence(\"thank god my brain compensated.|||definitely Walter White, your most relatable tv psychopath.\"), Sentence(\"i'm in awe and at the same time horried of his whole progression from boring old chemistry teacher to master manipulator devil incarnate.\"), Sentence(\"i...'\")]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "6    None\n",
       "7    None\n",
       "8    None\n",
       "9    None\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF['text'].apply(lambda x: print(textblob.TextBlob(x).sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun_count Done\n",
      "verb_count Done\n",
      "adj_count Done\n",
      "adv_count Done\n",
      "pron_count Done\n",
      "positive_count Done\n",
      "positive_by_negative Done\n",
      "positive_by_negative Done\n",
      "subjective_count Done\n",
      "objective_count Done\n"
     ]
    }
   ],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "def count_polarity(x):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for sentence in wiki.sentences:\n",
    "            if sentence.sentiment.polarity>0:\n",
    "                positive += 1\n",
    "            else:\n",
    "                negative += 1\n",
    "           \n",
    "    except:\n",
    "        pass\n",
    "    return positive/negative\n",
    "\n",
    "\n",
    "def positive_polarity_count(x):\n",
    "    positive = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for sentence in wiki.sentences:\n",
    "            if sentence.sentiment.polarity>0.3:\n",
    "                positive += 1           \n",
    "    except:\n",
    "        pass\n",
    "    return positive\n",
    "\n",
    "def negative_polarity_count(x):\n",
    "    negative = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for sentence in wiki.sentences:\n",
    "            if sentence.sentiment.polarity<0.3:\n",
    "                negative += 1           \n",
    "    except:\n",
    "        pass\n",
    "    return negative\n",
    "\n",
    "def subjectivity_count(x):\n",
    "    subjective_count = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for sentence in wiki.sentences:\n",
    "            if sentence.sentiment.subjectivity>0.7:\n",
    "                subjective_count += 1           \n",
    "    except:\n",
    "        pass\n",
    "    return subjective_count\n",
    "\n",
    "\n",
    "def objectivity_count(x):\n",
    "    objective_count = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for sentence in wiki.sentences:\n",
    "            if sentence.sentiment.subjectivity<0.3:\n",
    "                objective_count += 1           \n",
    "    except:\n",
    "        pass\n",
    "    return objective_count\n",
    "\n",
    "\n",
    "trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "print(\"noun_count Done\")\n",
    "trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "print(\"verb_count Done\")\n",
    "trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "print(\"adj_count Done\")\n",
    "trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "print(\"adv_count Done\")\n",
    "trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "print(\"pron_count Done\")\n",
    "trainDF['positive_count'] = trainDF['text'].apply(lambda x: positive_polarity_count(x))\n",
    "print(\"positive_count Done\")\n",
    "trainDF['negative_count'] = trainDF['text'].apply(lambda x: negative_polarity_count(x))\n",
    "print(\"negative_count Done\")\n",
    "trainDF['positive_by_negative'] = trainDF['text'].apply(lambda x: count_polarity(x))\n",
    "print(\"positive_by_negative Done\")\n",
    "trainDF['subjective_count'] = trainDF['text'].apply(lambda x: subjectivity_count(x))\n",
    "print(\"subjective_count Done\")\n",
    "trainDF['objective_count'] = trainDF['text'].apply(lambda x: objectivity_count(x))\n",
    "print(\"objective_count Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>decimal_or_digit_count</th>\n",
       "      <th>positive_by_negative</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>subjective_count</th>\n",
       "      <th>objective_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>4652</td>\n",
       "      <td>556</td>\n",
       "      <td>8.351885</td>\n",
       "      <td>519</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>199</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>7053</td>\n",
       "      <td>1170</td>\n",
       "      <td>6.023057</td>\n",
       "      <td>529</td>\n",
       "      <td>154</td>\n",
       "      <td>82</td>\n",
       "      <td>274</td>\n",
       "      <td>258</td>\n",
       "      <td>96</td>\n",
       "      <td>85</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>INTP</td>\n",
       "      <td>5265</td>\n",
       "      <td>836</td>\n",
       "      <td>6.290323</td>\n",
       "      <td>416</td>\n",
       "      <td>89</td>\n",
       "      <td>26</td>\n",
       "      <td>195</td>\n",
       "      <td>164</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>6271</td>\n",
       "      <td>1064</td>\n",
       "      <td>5.888263</td>\n",
       "      <td>459</td>\n",
       "      <td>98</td>\n",
       "      <td>57</td>\n",
       "      <td>230</td>\n",
       "      <td>238</td>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>6111</td>\n",
       "      <td>967</td>\n",
       "      <td>6.313017</td>\n",
       "      <td>442</td>\n",
       "      <td>86</td>\n",
       "      <td>35</td>\n",
       "      <td>238</td>\n",
       "      <td>233</td>\n",
       "      <td>94</td>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>8589</td>\n",
       "      <td>1491</td>\n",
       "      <td>5.756702</td>\n",
       "      <td>548</td>\n",
       "      <td>196</td>\n",
       "      <td>74</td>\n",
       "      <td>351</td>\n",
       "      <td>336</td>\n",
       "      <td>110</td>\n",
       "      <td>125</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>7916</td>\n",
       "      <td>1329</td>\n",
       "      <td>5.951880</td>\n",
       "      <td>558</td>\n",
       "      <td>118</td>\n",
       "      <td>63</td>\n",
       "      <td>291</td>\n",
       "      <td>288</td>\n",
       "      <td>120</td>\n",
       "      <td>138</td>\n",
       "      <td>179</td>\n",
       "      <td>9</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>6900</td>\n",
       "      <td>1223</td>\n",
       "      <td>5.637255</td>\n",
       "      <td>381</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>284</td>\n",
       "      <td>274</td>\n",
       "      <td>107</td>\n",
       "      <td>97</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm not sure, that's a good question. The dist...</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>5325</td>\n",
       "      <td>738</td>\n",
       "      <td>7.205683</td>\n",
       "      <td>545</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>226</td>\n",
       "      <td>154</td>\n",
       "      <td>73</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
       "      <td>INTP</td>\n",
       "      <td>7573</td>\n",
       "      <td>1233</td>\n",
       "      <td>6.136953</td>\n",
       "      <td>475</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>331</td>\n",
       "      <td>255</td>\n",
       "      <td>128</td>\n",
       "      <td>155</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  char_count  \\\n",
       "0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...  INFJ        4652   \n",
       "1  'I'm finding the lack of me in these posts ver...  ENTP        7053   \n",
       "2  'Good one  _____   https://www.youtube.com/wat...  INTP        5265   \n",
       "3  'Dear INTP,   I enjoyed our conversation the o...  INTJ        6271   \n",
       "4  'You're fired.|||That's another silly misconce...  ENTJ        6111   \n",
       "5  '18/37 @.@|||Science  is not perfect. No scien...  INTJ        8589   \n",
       "6  'No, I can't draw on my own nails (haha). Thos...  INFJ        7916   \n",
       "7  'I tend to build up a collection of things on ...  INTJ        6900   \n",
       "8  I'm not sure, that's a good question. The dist...  INFJ        5325   \n",
       "9  'https://www.youtube.com/watch?v=w8-egj0y8Qs||...  INTP        7573   \n",
       "\n",
       "   word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         556      8.351885                519                30   \n",
       "1        1170      6.023057                529               154   \n",
       "2         836      6.290323                416                89   \n",
       "3        1064      5.888263                459                98   \n",
       "4         967      6.313017                442                86   \n",
       "5        1491      5.756702                548               196   \n",
       "6        1329      5.951880                558               118   \n",
       "7        1223      5.637255                381                48   \n",
       "8         738      7.205683                545                85   \n",
       "9        1233      6.136953                475                40   \n",
       "\n",
       "   upper_case_word_count  noun_count  verb_count  adj_count  adv_count  \\\n",
       "0                     13         199          95         65         41   \n",
       "1                     82         274         258         96         85   \n",
       "2                     26         195         164         86         96   \n",
       "3                     57         230         238         99        107   \n",
       "4                     35         238         233         94         80   \n",
       "5                     74         351         336        110        125   \n",
       "6                     63         291         288        120        138   \n",
       "7                      8         284         274        107         97   \n",
       "8                     17         226         154         73         58   \n",
       "9                     14         331         255        128        155   \n",
       "\n",
       "   pron_count  decimal_or_digit_count  positive_by_negative  positive_count  \\\n",
       "0          47                       1              1.000000               5   \n",
       "1         188                       1              0.822222              16   \n",
       "2          93                       5              1.000000              12   \n",
       "3         150                       5              0.763158              11   \n",
       "4         121                       1              0.650000               9   \n",
       "5         178                       2              0.616667              16   \n",
       "6         179                       9              0.756098              12   \n",
       "7         120                       3              0.457143               4   \n",
       "8          68                       0              2.888889               7   \n",
       "9         100                       3              0.967742              15   \n",
       "\n",
       "   negative_count  subjective_count  objective_count  \n",
       "0              19                 4               10  \n",
       "1              63                15               36  \n",
       "2              30                 9               14  \n",
       "3              55                13               28  \n",
       "4              57                11               30  \n",
       "5              81                12               41  \n",
       "6              60                 9               24  \n",
       "7              46                 1               25  \n",
       "8              27                 8                5  \n",
       "9              45                10               22  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.to_pickle(\"trainDF_final_after_POS_tagging.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trainDF = pd.read_pickle(\"trainDF_final_after_POS_tagging.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(xtrain_count)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# view the topic models\n",
    "n_top_words = 2\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to i',\n",
       " 'i the',\n",
       " 'i the',\n",
       " 'idea hate',\n",
       " 'i the',\n",
       " 'remind anywhere',\n",
       " 'io hold',\n",
       " 'to the',\n",
       " 'see give',\n",
       " 'externally sake',\n",
       " 'to i',\n",
       " 'i the',\n",
       " 'i the',\n",
       " 'the i',\n",
       " 'wellbeing receipt',\n",
       " 'i and',\n",
       " 'idealistic hgkli',\n",
       " 'i the',\n",
       " 'i and',\n",
       " 'com the']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    if is_neural_net:\n",
    "        classifier.fit(feature_vector_train, label,epochs=10)\n",
    "    else:\n",
    "        classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.0\n",
      "NB, WordLevel TF-IDF:  0.0\n",
      "NB, N-Gram Vectors:  0.0\n",
      "NB, CharLevel Vectors:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.0\n",
      "LR, WordLevel TF-IDF:  0.0\n",
      "LR, N-Gram Vectors:  0.0\n",
      "LR, CharLevel Vectors:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.0\n",
      "SVM, CharLevel Vectors:  0.0\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"SVM, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.0\n",
      "RF, WordLevel TF-IDF:  0.0\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, WordLevel TF-IDF:  0.3333333333333333\n",
      "Xgb, CharLevel Vectors:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print(\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print(\"Xgb, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.7303\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -16.4744\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: -25.0502\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: -25.0523\n",
      "NN, Ngram Level TF IDF Vectors 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def create_model_architecture(input_size):\n",
    "    # create input layer \n",
    "    input_layer = layers.Input((input_size, ), sparse=True)\n",
    "    \n",
    "    # create hidden layer\n",
    "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    # create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    classifier = models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(lr=0.1), loss='binary_crossentropy')\n",
    "    return classifier \n",
    "\n",
    "classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "accuracy = train_model(classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, is_neural_net=True)\n",
    "print(\"NN, Ngram Level TF IDF Vectors\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ae63abb2074>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pandas_embeddings.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.DataFrame(embedding_matrix).to_pickle(\"pandas_embeddings.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "embedding_matrix = pd.read_pickle(\"pandas_embeddings.pkl\")\n",
    "embedding_matrix = np.array(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cd95790f40bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_seq_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_seq_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_neural_net\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CNN, Word Embeddings\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cd95790f40bd>\u001b[0m in \u001b[0;36mcreate_cnn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Add an Input Layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Add the word embedding Layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "def create_cnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((2000, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_cnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"CNN, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 5s 701ms/step - loss: 0.7972\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 3s 494ms/step - loss: 0.7340\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 485ms/step - loss: 0.5701\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.4256\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 3s 487ms/step - loss: 0.4152\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 493ms/step - loss: 0.2081\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 485ms/step - loss: 0.0439\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 4s 501ms/step - loss: -0.0304\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 495ms/step - loss: -0.2111\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 4s 545ms/step - loss: -0.3851\n",
      "RNN-LSTM, Word Embeddings 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_lstm():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((2000, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_lstm()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-LSTM, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 5s 685ms/step - loss: 0.6773\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.5643\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 400ms/step - loss: 0.5306\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 3s 394ms/step - loss: 0.4391\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 3s 375ms/step - loss: 0.2794\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.2129\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 377ms/step - loss: -0.0652\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 3s 384ms/step - loss: -0.1889\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 372ms/step - loss: -0.2918\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 400ms/step - loss: -0.4005\n",
      "RNN-GRU, Word Embeddings 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_gru():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((2000, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the GRU Layer\n",
    "    lstm_layer = layers.GRU(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_gru()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-GRU, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6940\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 7s 972ms/step - loss: 0.6785\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 6s 884ms/step - loss: 0.4905\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 6s 840ms/step - loss: 0.5077\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.4424\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 6s 893ms/step - loss: 0.2375\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 6s 874ms/step - loss: 0.2760\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 6s 857ms/step - loss: 0.0014\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 6s 864ms/step - loss: -0.1332\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 6s 879ms/step - loss: -0.2102\n",
      "RNN-Bidirectional, Word Embeddings 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def create_bidirectional_rnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((2000, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_bidirectional_rnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-Bidirectional, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\pratikp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "def create_rcnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((2000, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "    \n",
    "    # Add the recurrent layer\n",
    "    rnn_layer = layers.Bidirectional(layers.GRU(50, return_sequences=True))(embedding_layer)\n",
    "    \n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rcnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"CNN, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"trainDF_final_after_POS_tagging.plk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:1000,2:]\n",
    "y = df.iloc[:1000,1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, y)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgboost.XGBClassifier()\n",
    "classifier.fit(train_x, train_y)\n",
    "    \n",
    "# predict the labels on validation dataset\n",
    "predictions = classifier.predict(valid_x)\n",
    "\n",
    "classifier.score(valid_x,valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
